#!/usr/bin/env python3
"""
DB to JSON Migration Script
SQLite DBì˜ ëª¨ë“  ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜
"""

import sqlite3
import json
import os
from datetime import datetime
from json_data_manager import JSONDataManager

def migrate_database_to_json(db_path: str = 'progress_report.db'):
    """DB ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜"""
    print("ğŸ”„ DB to JSON ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
    
    # JSON ë°ì´í„° ë§¤ë‹ˆì € ì´ˆê¸°í™”
    json_manager = JSONDataManager()
    
    try:
        # DB ì—°ê²°
        conn = sqlite3.connect(db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # ===========================================
        # 1. ì‚¬ìš©ì ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
        # ===========================================
        print("ğŸ‘¥ ì‚¬ìš©ì ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘...")
        try:
            cursor.execute("SELECT * FROM users")
            users = []
            for row in cursor.fetchall():
                user_data = {
                    'id': row['id'],
                    'username': row['username'],
                    'password_hash': row['password_hash'],
                    'first_name': row['first_name'],
                    'last_name': row['last_name'],
                    'role': row['role'],
                    'position': row['position'],
                    'location': row['location'],
                    'is_active': bool(row['is_active']),
                    'created_at': row['created_at'],
                    'updated_at': row['updated_at']
                }
                users.append(user_data)
            
            json_manager._save_json(
                json_manager._get_file_path("users", "users.json"), 
                users
            )
            print(f"âœ… ì‚¬ìš©ì {len(users)}ëª… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ì‚¬ìš©ì ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        
        # ===========================================
        # 2. FCM í† í° ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
        # ===========================================
        print("ğŸ“± FCM í† í° ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘...")
        try:
            cursor.execute("SELECT * FROM fcm_tokens")
            tokens = []
            for row in cursor.fetchall():
                token_data = {
                    'id': row['id'],
                    'user_id': row['user_id'],
                    'token': row['token'],
                    'device_info': row['device_info'],
                    'created_at': row['created_at'],
                    'last_used': row['last_used'],
                    'is_active': bool(row['is_active'])
                }
                tokens.append(token_data)
            
            json_manager._save_json(
                json_manager._get_file_path("fcm", "tokens.json"), 
                tokens
            )
            print(f"âœ… FCM í† í° {len(tokens)}ê°œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ FCM í† í° ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        
        # ===========================================
        # 3. ì ‘ê·¼ ë¡œê·¸ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
        # ===========================================
        print("ğŸ“Š ì ‘ê·¼ ë¡œê·¸ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘...")
        try:
            cursor.execute("SELECT * FROM access_logs ORDER BY timestamp DESC LIMIT 1000")
            access_logs = []
            for row in cursor.fetchall():
                log_data = {
                    'id': row['id'],
                    'timestamp': row['timestamp'],
                    'user_id': row['user_id'],
                    'username': row['username'],
                    'display_name': row['display_name'],
                    'role': row['role'],
                    'position': row['position'],
                    'ip_address': row['ip_address'],
                    'user_agent': row['user_agent'],
                    'page_accessed': row['page_accessed'],
                    'session_duration': row['session_duration']
                }
                access_logs.append(log_data)
            
            json_manager._save_json(
                json_manager._get_file_path("logs", "access_logs.json"), 
                access_logs
            )
            print(f"âœ… ì ‘ê·¼ ë¡œê·¸ {len(access_logs)}ê°œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ì ‘ê·¼ ë¡œê·¸ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        
        # ===========================================
        # 4. Progress Note ë¡œê·¸ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
        # ===========================================
        print("ğŸ“ Progress Note ë¡œê·¸ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘...")
        try:
            cursor.execute("SELECT * FROM progress_note_logs ORDER BY timestamp DESC LIMIT 1000")
            progress_logs = []
            for row in cursor.fetchall():
                log_data = {
                    'id': row['id'],
                    'timestamp': row['timestamp'],
                    'user_id': row['user_id'],
                    'username': row['username'],
                    'client_id': row['client_id'],
                    'client_name': row['client_name'],
                    'site': row['site'],
                    'action': row['action'],
                    'note_id': row['note_id'],
                    'details': row['details']
                }
                progress_logs.append(log_data)
            
            json_manager._save_json(
                json_manager._get_file_path("logs", "progress_note_logs.json"), 
                progress_logs
            )
            print(f"âœ… Progress Note ë¡œê·¸ {len(progress_logs)}ê°œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ Progress Note ë¡œê·¸ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        
        # ===========================================
        # 5. í´ë¼ì´ì–¸íŠ¸ ìºì‹œ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
        # ===========================================
        print("ğŸ‘¤ í´ë¼ì´ì–¸íŠ¸ ìºì‹œ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘...")
        try:
            cursor.execute("SELECT DISTINCT site FROM clients_cache")
            sites = [row[0] for row in cursor.fetchall()]
            
            for site in sites:
                cursor.execute("SELECT * FROM clients_cache WHERE site = ?", (site,))
                clients = []
                for row in cursor.fetchall():
                    client_data = {
                        'id': row['id'],
                        'person_id': row['person_id'],
                        'first_name': row['first_name'],
                        'last_name': row['last_name'],
                        'date_of_birth': row['date_of_birth'],
                        'site': row['site'],
                        'cached_at': row['cached_at'],
                        'is_active': bool(row['is_active'])
                    }
                    clients.append(client_data)
                
                filename = f"clients_{site.replace(' ', '_').lower()}.json"
                json_manager._save_json(
                    json_manager._get_file_path("cache", filename), 
                    clients
                )
                print(f"  âœ… {site}: {len(clients)}ëª… í´ë¼ì´ì–¸íŠ¸ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ í´ë¼ì´ì–¸íŠ¸ ìºì‹œ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        
        # ===========================================
        # 6. ì¼€ì–´ ì˜ì—­ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
        # ===========================================
        print("ğŸ¥ ì¼€ì–´ ì˜ì—­ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘...")
        try:
            cursor.execute("SELECT * FROM care_areas")
            care_areas = []
            for row in cursor.fetchall():
                care_area_data = {
                    'id': row['id'],
                    'care_area_id': row['care_area_id'],
                    'name': row['name'],
                    'description': row['description'],
                    'is_archived': bool(row['is_archived']),
                    'cached_at': row['cached_at']
                }
                care_areas.append(care_area_data)
            
            json_manager._save_json(
                json_manager._get_file_path("cache", "care_areas.json"), 
                care_areas
            )
            print(f"âœ… ì¼€ì–´ ì˜ì—­ {len(care_areas)}ê°œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ì¼€ì–´ ì˜ì—­ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        
        # ===========================================
        # 7. ì´ë²¤íŠ¸ íƒ€ì… ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
        # ===========================================
        print("ğŸ“‹ ì´ë²¤íŠ¸ íƒ€ì… ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘...")
        try:
            cursor.execute("SELECT * FROM event_types")
            event_types = []
            for row in cursor.fetchall():
                event_type_data = {
                    'id': row['id'],
                    'event_type_id': row['event_type_id'],
                    'name': row['name'],
                    'description': row['description'],
                    'is_archived': bool(row['is_archived']),
                    'cached_at': row['cached_at']
                }
                event_types.append(event_type_data)
            
            json_manager._save_json(
                json_manager._get_file_path("cache", "event_types.json"), 
                event_types
            )
            print(f"âœ… ì´ë²¤íŠ¸ íƒ€ì… {len(event_types)}ê°œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ì´ë²¤íŠ¸ íƒ€ì… ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        
        # ===========================================
        # 8. ì¸ì‹œë˜íŠ¸ ìºì‹œ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
        # ===========================================
        print("ğŸš¨ ì¸ì‹œë˜íŠ¸ ìºì‹œ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘...")
        try:
            cursor.execute("SELECT DISTINCT site FROM incidents_cache")
            sites = [row[0] for row in cursor.fetchall()]
            
            for site in sites:
                cursor.execute("SELECT * FROM incidents_cache WHERE site = ?", (site,))
                incidents = []
                for row in cursor.fetchall():
                    incident_data = {
                        'id': row['id'],
                        'incident_id': row['incident_id'],
                        'client_id': row['client_id'],
                        'client_name': row['client_name'],
                        'incident_date': row['incident_date'],
                        'incident_type': row['incident_type'],
                        'description': row['description'],
                        'site': row['site'],
                        'cached_at': row['cached_at']
                    }
                    incidents.append(incident_data)
                
                filename = f"incidents_{site.replace(' ', '_').lower()}.json"
                json_manager._save_json(
                    json_manager._get_file_path("cache", filename), 
                    incidents
                )
                print(f"  âœ… {site}: {len(incidents)}ê°œ ì¸ì‹œë˜íŠ¸ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ì¸ì‹œë˜íŠ¸ ìºì‹œ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        
        # ===========================================
        # 9. ì‚¬ì´íŠ¸ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
        # ===========================================
        print("ğŸ¢ ì‚¬ì´íŠ¸ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘...")
        try:
            cursor.execute("SELECT * FROM sites")
            sites = []
            for row in cursor.fetchall():
                site_data = {
                    'id': row['id'],
                    'site_name': row['site_name'],
                    'server_ip': row['server_ip'],
                    'description': row['description'],
                    'is_active': bool(row['is_active']),
                    'created_at': row['created_at']
                }
                sites.append(site_data)
            
            json_manager._save_json(
                json_manager._get_file_path("system", "sites.json"), 
                sites
            )
            print(f"âœ… ì‚¬ì´íŠ¸ {len(sites)}ê°œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ì‚¬ì´íŠ¸ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        
        # ===========================================
        # 10. ë™ê¸°í™” ìƒíƒœ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
        # ===========================================
        print("ğŸ”„ ë™ê¸°í™” ìƒíƒœ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘...")
        try:
            cursor.execute("SELECT * FROM sync_status")
            sync_status = []
            for row in cursor.fetchall():
                sync_data = {
                    'id': row['id'],
                    'data_type': row['data_type'],
                    'site': row['site'],
                    'sync_status': row['sync_status'],
                    'last_sync_time': row['last_sync_time'],
                    'records_synced': row['records_synced'],
                    'error_message': row['error_message']
                }
                sync_status.append(sync_data)
            
            json_manager._save_json(
                json_manager._get_file_path("system", "sync_status.json"), 
                sync_status
            )
            print(f"âœ… ë™ê¸°í™” ìƒíƒœ {len(sync_status)}ê°œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ë™ê¸°í™” ìƒíƒœ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        
        # ===========================================
        # 11. API í‚¤ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
        # ===========================================
        print("ğŸ”‘ API í‚¤ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘...")
        try:
            cursor.execute("SELECT * FROM api_keys")
            api_keys = []
            for row in cursor.fetchall():
                api_key_data = {
                    'id': row['id'],
                    'site_name': row['site_name'],
                    'api_key': row['api_key'],
                    'server_url': row['server_url'],
                    'created_at': row['created_at'],
                    'updated_at': row['updated_at']
                }
                api_keys.append(api_key_data)
            
            json_manager._save_json(
                json_manager._get_file_path("api_keys", "api_keys.json"), 
                api_keys
            )
            print(f"âœ… API í‚¤ {len(api_keys)}ê°œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ API í‚¤ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        
        print("\nğŸ‰ DB to JSON ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
        
        # ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼ ìš”ì•½
        data_info = json_manager.get_data_info()
        print("\nğŸ“Š ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼:")
        for key, value in data_info.items():
            print(f"  {key}: {value}")
        
    except Exception as e:
        print(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
    finally:
        conn.close()

def main():
    print("ğŸ”„ DB to JSON ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬")
    print("=" * 50)
    
    db_path = input("DB íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ê¸°ë³¸ê°’: progress_report.db): ").strip()
    if not db_path:
        db_path = "progress_report.db"
    
    if not os.path.exists(db_path):
        print(f"âŒ DB íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {db_path}")
        return
    
    print(f"ğŸ“ ëŒ€ìƒ DB: {db_path}")
    
    # ë°±ì—… ìƒì„±
    backup_path = f"{db_path}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    try:
        import shutil
        shutil.copy2(db_path, backup_path)
        print(f"âœ… ë°±ì—… ìƒì„±: {backup_path}")
    except Exception as e:
        print(f"âŒ ë°±ì—… ìƒì„± ì‹¤íŒ¨: {e}")
        return
    
    # ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
    migrate_database_to_json(db_path)
    
    print(f"\nğŸ“„ JSON íŒŒì¼ë“¤ì´ 'data' ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("âš ï¸  ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ í›„ DB íŒŒì¼ì„ ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
