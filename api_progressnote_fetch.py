#!/usr/bin/env python3
"""
í”„ë¡œê·¸ë ˆìŠ¤ ë…¸íŠ¸ ì¡°íšŒ API í´ë¼ì´ì–¸íŠ¸
ì‚¬ì´íŠ¸ë³„ë¡œ í”„ë¡œê·¸ë ˆìŠ¤ ë…¸íŠ¸ë¥¼ ê°€ì ¸ì™€ì„œ IndexedDBì— ì €ì¥í•˜ëŠ” ê¸°ëŠ¥
"""

import requests
import logging
import os
import json
from datetime import datetime, timedelta
from typing import Optional, Dict, Any, List
from config import SITE_SERVERS, API_HEADERS, get_api_headers

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

class ProgressNoteFetchClient:
    """í”„ë¡œê·¸ë ˆìŠ¤ ë…¸íŠ¸ ì¡°íšŒ API í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, site: str):
        """
        Args:
            site: ì‚¬ì´íŠ¸ëª… (ì˜ˆ: 'Parafield Gardens', 'Nerrilda')
        """
        self.site = site
        self.server_ip = SITE_SERVERS.get(site)
        
        if not self.server_ip:
            logger.error(f"Unknown site: {site}. Available sites: {list(SITE_SERVERS.keys())}")
            raise ValueError(f"Unknown site: {site}")
        
        # server_ipì— ì´ë¯¸ í¬íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        self.base_url = f"http://{self.server_ip}"
        self.api_url = f"{self.base_url}/api/progressnote/details"
        
        # ì„¸ì…˜ ìƒì„±
        self.session = requests.Session()
        # ì‚¬ì´íŠ¸ë³„ API í—¤ë” ì„¤ì •
        site_headers = get_api_headers(site)
        self.session.headers.update(site_headers)
        
        logger.info(f"ProgressNoteFetchClient initialized for site: {site} ({self.server_ip})")
        logger.info(f"API URL: {self.api_url}")
        logger.info(f"Session headers: {dict(self.session.headers)}")
    
    def fetch_progress_notes(self, 
                           start_date: Optional[datetime] = None,
                           end_date: Optional[datetime] = None,
                           limit: int = 500, # Default limit
                           progress_note_event_type_id: Optional[int] = None) -> tuple[bool, Optional[List[Dict[str, Any]]]]:
        """
        íŠ¹ì • ì¡°ê±´ì— ë§ëŠ” í”„ë¡œê·¸ë ˆìŠ¤ ë…¸íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Args:
            start_date: ì‹œì‘ ë‚ ì§œ (ê¸°ë³¸ê°’: 14ì¼ ì „)
            end_date: ì¢…ë£Œ ë‚ ì§œ (ê¸°ë³¸ê°’: í˜„ì¬ ì‹œê°„)
            limit: ê°€ì ¸ì˜¬ ìµœëŒ€ ê°œìˆ˜ (ê¸°ë³¸ê°’: 500)
            progress_note_event_type_id: íŠ¹ì • ì´ë²¤íŠ¸ íƒ€ì… IDë¡œ í•„í„°ë§
            
        Returns:
            (ì„±ê³µ ì—¬ë¶€, ë°ì´í„° ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” None)
        """
        try:
            # ê¸°ë³¸ê°’ ì„¤ì •
            if start_date is None:
                start_date = datetime.now() - timedelta(days=14)
            if end_date is None:
                end_date = datetime.now()
            
            # API íŒŒë¼ë¯¸í„° ì„¤ì •
            params = {}
            
            # ë‚ ì§œ í˜•ì‹ ë³€í™˜ (POSTMANê³¼ ë™ì¼í•œ í˜•ì‹ ì‚¬ìš©)
            start_date_str = start_date.strftime('%Y-%m-%dT00:00:00Z')
            end_date_str = end_date.strftime('%Y-%m-%dT23:59:59Z')
            
            # ì´ë²¤íŠ¸ íƒ€ì… í•„í„°ë§
            if progress_note_event_type_id is not None:
                params['progressNoteEventTypeId'] = progress_note_event_type_id
            
            # ë‚ ì§œ í•„í„° ì ìš© - POSTMANê³¼ ë™ì¼í•œ í˜•ì‹ ì‚¬ìš© (gt: >, lt: <)
            params['date'] = [f'gt:{start_date_str}', f'lt:{end_date_str}']
            
            # Limit íŒŒë¼ë¯¸í„° ì„¤ì •
            if limit is not None:
                params['limit'] = limit
            
            # API ìš”ì²­
            response = self.session.get(
                self.api_url,
                params=params,
                timeout=120  # íƒ€ì„ì•„ì›ƒì„ 2ë¶„ìœ¼ë¡œ ì¦ê°€
            )
            
            if response.status_code == 200:
                data = response.json()
                logger.info(f"Successfully fetched {len(data)} progress notes from {self.site}")
                
                # ì‘ë‹µ ë°ì´í„° ìƒ˜í”Œ ë¡œê¹… (íŒŒì¼ë¡œë§Œ ì €ì¥)
                if data and len(data) > 0:
                    debug_info = {
                        'timestamp': datetime.now().isoformat(),
                        'site': self.site,
                        'api_url': self.api_url,
                        'params': params,
                        'date_range': f"{start_date_str} to {end_date_str}",
                        'event_type_filter': progress_note_event_type_id,
                        'limit': params.get('limit'),
                        'response_status': response.status_code,
                        'records_fetched': len(data),
                        'sample_records': []
                    }
                    
                    for i, record in enumerate(data[:3]):
                        event_type = record.get('ProgressNoteEventType', {})
                        debug_info['sample_records'].append({
                            'index': i+1,
                            'id': record.get('Id'),
                            'event_date': record.get('EventDate'),
                            'event_type': event_type.get('Description', 'N/A')
                        })
                    
                    # Save debug info to file
                    try:
                        logs_dir = os.path.join(os.getcwd(), 'logs')
                        os.makedirs(logs_dir, exist_ok=True)
                        timestamp = datetime.now().strftime('%Y-%m-%d_%H%M%S')
                        filename = f'api_debug_{timestamp}.json'
                        filepath = os.path.join(logs_dir, filename)
                        
                        with open(filepath, 'w', encoding='utf-8') as f:
                            json.dump(debug_info, f, indent=2, ensure_ascii=False)
                    except Exception as e:
                        logger.error(f"Failed to save debug log: {str(e)}")
                else:
                    logger.info("No data returned from API")
                
                return True, data
            else:
                logger.error(f"API request failed: {response.status_code} - {response.text}")
                # API ì‹¤íŒ¨ì‹œ ìƒì„¸í•œ ì—ëŸ¬ ì •ë³´ ì œê³µ
                error_details = {
                    'status_code': response.status_code,
                    'response_text': response.text,
                    'api_url': self.api_url,
                    'params': params,
                    'site': self.site,
                    'timestamp': datetime.now().isoformat()
                }
                logger.error(f"API ì‹¤íŒ¨ ìƒì„¸ ì •ë³´: {error_details}")
                return False, None
                
        except requests.exceptions.Timeout:
            logger.error(f"Request timed out after 120 seconds for {self.site}")
            return False, None
        except requests.exceptions.ConnectionError as e:
            logger.error(f"Connection error while fetching progress notes from {self.site}: {str(e)}")
            return False, None
        except Exception as e:
            logger.error(f"Unexpected error while fetching progress notes from {self.site}: {str(e)}")
            return False, None
    
    def fetch_recent_progress_notes(self, days: int = 14, limit: Optional[int] = None) -> tuple[bool, Optional[List[Dict[str, Any]]]]:
        """
        ìµœê·¼ Nì¼ê°„ì˜ í”„ë¡œê·¸ë ˆìŠ¤ ë…¸íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Args:
            days: ê°€ì ¸ì˜¬ ì¼ìˆ˜ (ê¸°ë³¸ê°’: 14ì¼)
            limit: ìµœëŒ€ ê°œìˆ˜ (Noneì´ë©´ ê¸°ë³¸ê°’ 500 ì‚¬ìš©)
            
        Returns:
            (ì„±ê³µ ì—¬ë¶€, ë°ì´í„° ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” None)
        """
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        effective_limit = limit if limit is not None else 500
        return self.fetch_progress_notes(start_date, end_date, limit=effective_limit)
    
    def fetch_progress_notes_since(self, since_date: datetime) -> tuple[bool, Optional[List[Dict[str, Any]]]]:
        """
        íŠ¹ì • ë‚ ì§œ ì´í›„ì˜ í”„ë¡œê·¸ë ˆìŠ¤ ë…¸íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤ (ì¦ë¶„ ì—…ë°ì´íŠ¸ìš©).
        
        Args:
            since_date: ì‹œì‘ ë‚ ì§œ
            
        Returns:
            (ì„±ê³µ ì—¬ë¶€, ë°ì´í„° ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” None)
        """
        end_date = datetime.now()
        logger.info(f"Incremental update - since_date: {since_date}, end_date: {end_date}")
        logger.info(f"Time difference: {end_date - since_date}")
        
        success, data = self.fetch_progress_notes(since_date, end_date)
        
        if success and data:
            logger.info(f"Incremental update found {len(data)} records")
            # ìµœì‹  ê¸°ë¡ ëª‡ ê°œ ë¡œê¹…
            if len(data) > 0:
                logger.info("Latest records in incremental update:")
                for i, record in enumerate(data[:5]):
                    logger.info(f"  {i+1}. ID: {record.get('Id')}, EventDate: {record.get('EventDate')}, CreatedDate: {record.get('CreatedDate', 'N/A')}")
        else:
            logger.info("No new records found in incremental update")
            
        return success, data

    def fetch_rod_progress_notes(self, year: int, month: int, event_types: List[str] = None) -> tuple[bool, Optional[List[Dict[str, Any]]]]:
        """
        ROD ëŒ€ì‹œë³´ë“œìš© í”„ë¡œê·¸ë ˆìŠ¤ ë…¸íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Args:
            year: ë…„ë„
            month: ì›”
            event_types: í•„í„°ë§í•  ì´ë²¤íŠ¸ íƒ€ì… ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ìë™ìœ¼ë¡œ "Resident of the day" ì´ë²¤íŠ¸ íƒ€ì… ì°¾ê¸°)
            
        Returns:
            (ì„±ê³µ ì—¬ë¶€, ë°ì´í„° ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” None)
        """
        try:
            logger.info(f"Fetching ROD progress notes for {year}-{month}, event_types: {event_types}")
            
            # ë…„ë„/ì›”ì— í•´ë‹¹í•˜ëŠ” ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
            start_date = datetime(year, month, 1)
            if month == 12:
                end_date = datetime(year + 1, 1, 1) - timedelta(days=1)
            else:
                end_date = datetime(year, month + 1, 1) - timedelta(days=1)
            
            logger.info(f"Date range: {start_date} to {end_date}")
            
            # ì´ë²¤íŠ¸ íƒ€ì…ì´ ì œê³µë˜ì§€ ì•Šì•˜ìœ¼ë©´ "Resident of the day" ì´ë²¤íŠ¸ íƒ€ì… ìë™ ì°¾ê¸°
            if not event_types or len(event_types) == 0:
                logger.info("No event types provided, searching for 'Resident of the day' event types")
                event_types = self.find_resident_of_day_event_types()
                if not event_types:
                    logger.error("No Resident of the day event types found")
                    return False, None
                logger.info(f"Found Resident of the day event types: {event_types}")
            
            # ì´ë²¤íŠ¸ íƒ€ì… ID ì°¾ê¸°
            event_type_ids = []
            for event_type_name in event_types:
                event_type_id = self._find_event_type_id(event_type_name)
                if event_type_id:
                    event_type_ids.append(event_type_id)
                    logger.info(f"Found event type ID {event_type_id} for '{event_type_name}'")
                else:
                    logger.warning(f"Event type '{event_type_name}' not found")
            
            if not event_type_ids:
                logger.error("No valid event type IDs found")
                return False, None
            
            # ê° ì´ë²¤íŠ¸ íƒ€ì…ë³„ë¡œ í”„ë¡œê·¸ë ˆìŠ¤ ë…¸íŠ¸ ê°€ì ¸ì˜¤ê¸°
            all_notes = []
            for event_type_id in event_type_ids:
                logger.info(f"Fetching notes for event type ID: {event_type_id}")
                success, notes = self.fetch_progress_notes(
                    start_date=start_date,
                    end_date=end_date,
                    progress_note_event_type_id=event_type_id
                )
                
                if success and notes:
                    logger.info(f"Found {len(notes)} notes for event type ID {event_type_id}")
                    all_notes.extend(notes)
                else:
                    logger.warning(f"No notes found for event type ID {event_type_id}")
            
            logger.info(f"Total ROD notes found: {len(all_notes)}")
            return True, all_notes
            
        except Exception as e:
            logger.error(f"Error fetching ROD progress notes: {str(e)}")
            return False, None
    
    def fetch_progress_notes_by_event_types(self, days: int, event_types: List[str]) -> tuple[bool, Optional[List[Dict[str, Any]]]]:
        """
        íŠ¹ì • ì´ë²¤íŠ¸ íƒ€ì…ë“¤ë¡œ í•„í„°ë§ëœ í”„ë¡œê·¸ë ˆìŠ¤ ë…¸íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Args:
            days: ê°€ì ¸ì˜¬ ì¼ìˆ˜
            event_types: í•„í„°ë§í•  ì´ë²¤íŠ¸ íƒ€ì… ë¦¬ìŠ¤íŠ¸
            
        Returns:
            (ì„±ê³µ ì—¬ë¶€, ë°ì´í„° ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” None)
        """
        try:
            logger.info(f"Fetching progress notes by event types: {event_types} for {days} days")
            
            # ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
            end_date = datetime.now()
            start_date = end_date - timedelta(days=days)
            
            logger.info(f"Date range: {start_date} to {end_date}")
            
            # ì´ë²¤íŠ¸ íƒ€ì… ID ì°¾ê¸°
            event_type_ids = []
            for event_type_name in event_types:
                event_type_id = self._find_event_type_id(event_type_name)
                if event_type_id:
                    event_type_ids.append(event_type_id)
                    logger.info(f"Found event type ID {event_type_id} for '{event_type_name}'")
                else:
                    logger.warning(f"Event type '{event_type_name}' not found")
            
            if not event_type_ids:
                logger.error("No valid event type IDs found")
                return False, None
            
            # ê° ì´ë²¤íŠ¸ íƒ€ì…ë³„ë¡œ í”„ë¡œê·¸ë ˆìŠ¤ ë…¸íŠ¸ ê°€ì ¸ì˜¤ê¸° (ì„±ëŠ¥ ìµœì í™”: limit ì œê±°)
            all_notes = []
            for event_type_id in event_type_ids:
                logger.info(f"Fetching notes for event type ID: {event_type_id}")
                success, notes = self.fetch_progress_notes(
                    start_date=start_date,
                    end_date=end_date,
                    limit=None,  # ì„±ëŠ¥ ìµœì í™”: limit ì œê±°
                    progress_note_event_type_id=event_type_id
                )
                
                if success and notes:
                    logger.info(f"Found {len(notes)} notes for event type ID {event_type_id}")
                    all_notes.extend(notes)
                else:
                    logger.warning(f"No notes found for event type ID {event_type_id}")
            
            logger.info(f"Total notes found for event types: {len(all_notes)}")
            return True, all_notes
            
        except Exception as e:
            logger.error(f"Error fetching progress notes by event types: {str(e)}")
            return False, None
    
    def find_resident_of_day_event_types(self) -> List[str]:
        """
        "Resident of the day" ê´€ë ¨ ì´ë²¤íŠ¸ íƒ€ì…ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤.
        
        Returns:
            "Resident of the day" ê´€ë ¨ ì´ë²¤íŠ¸ íƒ€ì… ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        """
        try:
            logger.info(f"Finding Resident of the day event types for site: {self.site}")
            
            # ì‚¬ì´íŠ¸ë³„ JSON íŒŒì¼ì—ì„œ ì´ë²¤íŠ¸ íƒ€ì… ë¡œë“œ
            from api_eventtype import get_site_event_types
            event_types = get_site_event_types(self.site)
            
            if not event_types:
                logger.error(f"Failed to load event types from JSON for site {self.site}")
                return []
            
            logger.info(f"Searching through {len(event_types)} event types for 'Resident of the day'")
            resident_of_day_types = []
            
            for event_type in event_types:
                description = event_type.get('Description', '')
                event_id = event_type.get('Id')
                
                if 'resident of the day' in description.lower():
                    logger.info(f"Found Resident of the day event type: '{description}' (ID: {event_id})")
                    resident_of_day_types.append(description)
            
            logger.info(f"Found {len(resident_of_day_types)} Resident of the day event types: {resident_of_day_types}")
            return resident_of_day_types
            
        except Exception as e:
            logger.error(f"Error finding Resident of the day event types: {str(e)}")
            return []
    
    def _find_event_type_id(self, event_type_name: str) -> Optional[int]:
        """
        ì´ë²¤íŠ¸ íƒ€ì… ì´ë¦„ìœ¼ë¡œ IDë¥¼ ì°¾ìŠµë‹ˆë‹¤.
        
        Args:
            event_type_name: ì´ë²¤íŠ¸ íƒ€ì… ì´ë¦„
            
        Returns:
            ì´ë²¤íŠ¸ íƒ€ì… ID ë˜ëŠ” None
        """
        try:
            logger.info(f"Finding event type ID for '{event_type_name}' in site: {self.site}")
            
            # ì‚¬ì´íŠ¸ë³„ JSON íŒŒì¼ì—ì„œ ì´ë²¤íŠ¸ íƒ€ì… ë¡œë“œ
            from api_eventtype import get_site_event_types
            event_types = get_site_event_types(self.site)
            
            if not event_types:
                logger.error(f"Failed to load event types from JSON for site {self.site}")
                return None
            
            logger.info(f"Found {len(event_types)} event types for site {self.site}")
            # ì´ë²¤íŠ¸ íƒ€ì… ì´ë¦„ìœ¼ë¡œ ID ì°¾ê¸°
            for event_type in event_types:
                description = event_type.get('Description', '')
                event_id = event_type.get('Id')
                if event_type_name.lower() in description.lower():
                    logger.info(f"Found matching event type: '{description}' (ID: {event_id})")
                    return event_id
            
            logger.warning(f"Event type '{event_type_name}' not found in {len(event_types)} available types")
            return None
            
        except Exception as e:
            logger.error(f"Error finding event type ID for '{event_type_name}': {str(e)}")
            return None

def fetch_progress_notes_for_site(site: str, days: int = 14, event_types: List[str] = None, year: int = None, month: int = None, client_service_id: int = None, limit: Optional[int] = None) -> tuple[bool, Optional[List[Dict[str, Any]]]]:
    """
    íŠ¹ì • ì‚¬ì´íŠ¸ì˜ í”„ë¡œê·¸ë ˆìŠ¤ ë…¸íŠ¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” í¸ì˜ í•¨ìˆ˜ (DB ì§ì ‘ ì ‘ì† ë˜ëŠ” API)
    
    Args:
        site: ì‚¬ì´íŠ¸ëª…
        days: ê°€ì ¸ì˜¬ ì¼ìˆ˜
        event_types: í•„í„°ë§í•  ì´ë²¤íŠ¸ íƒ€ì… ë¦¬ìŠ¤íŠ¸
        year: ë…„ë„ (ROD ëŒ€ì‹œë³´ë“œìš©)
        month: ì›” (ROD ëŒ€ì‹œë³´ë“œìš©)
        client_service_id: íŠ¹ì • í´ë¼ì´ì–¸íŠ¸ ì„œë¹„ìŠ¤ IDë¡œ í•„í„°ë§
        limit: ìµœëŒ€ ì¡°íšŒ ê°œìˆ˜ (Noneì´ë©´ DB 500/API ê¸°ë³¸ê°’ ì‚¬ìš©). filter endpointì—ì„œ ì „ì²´ë¥¼ í•œ ë²ˆì— ë°›ì„ ë•Œ í° ê°’ ì „ë‹¬.
        
    Returns:
        (ì„±ê³µ ì—¬ë¶€, ë°ì´í„° ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” None)
    """
    import sqlite3
    import os
    
    # DB ì§ì ‘ ì ‘ì† ëª¨ë“œ í™•ì¸
    use_db_direct = False
    try:
        conn = sqlite3.connect('progress_report.db', timeout=10)
        cursor = conn.cursor()
        cursor.execute("SELECT value FROM system_settings WHERE key = 'USE_DB_DIRECT_ACCESS'")
        result = cursor.fetchone()
        conn.close()
        
        if result and result[0]:
            use_db_direct = result[0].lower() == 'true'
        else:
            use_db_direct = os.environ.get('USE_DB_DIRECT_ACCESS', 'false').lower() == 'true'
    except:
        use_db_direct = os.environ.get('USE_DB_DIRECT_ACCESS', 'false').lower() == 'true'
    
    # DB ì§ì ‘ ì ‘ì† ëª¨ë“œ
    if use_db_direct:
        try:
            from manad_db_connector import MANADDBConnector
            from datetime import datetime, timedelta
            
            logger.info(f"ğŸ”Œ DB ì§ì ‘ ì ‘ì† ëª¨ë“œ: Progress Notes ì¡°íšŒ - {site}")
            connector = MANADDBConnector(site)
            
            # ROD ëŒ€ì‹œë³´ë“œìš© íŠ¹ë³„ ì²˜ë¦¬
            if year is not None and month is not None:
                start_date = datetime(year, month, 1)
                if month == 12:
                    end_date = datetime(year + 1, 1, 1) - timedelta(days=1)
                else:
                    end_date = datetime(year, month + 1, 1) - timedelta(days=1)
            else:
                end_date = datetime.now()
                start_date = end_date - timedelta(days=days)
            
            # Event Type í•„í„°ë§ (ID ë³€í™˜ í•„ìš”ì‹œ)
            event_type_id = None
            if event_types and len(event_types) > 0:
                # Event Type ì´ë¦„ìœ¼ë¡œ ID ì°¾ê¸° (ê°„ë‹¨í•œ ë²„ì „, ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•  ìˆ˜ ìˆìŒ)
                logger.warning(f"Event Type í•„í„°ë§ì€ DB ì§ì ‘ ì ‘ì† ëª¨ë“œì—ì„œ ì•„ì§ ì™„ì „íˆ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {event_types}")
            
            effective_limit = limit if limit is not None else 500
            logger.info(f"ğŸ” [FILTER] connector.fetch_progress_notes í˜¸ì¶œ - client_service_id={client_service_id}, limit={effective_limit}")
            logger.info(f"ğŸ” [FILTER] Parameters: start_date={start_date}, end_date={end_date}, limit={effective_limit}, event_type_id={event_type_id}, client_service_id={client_service_id}")
            progress_success, progress_notes = connector.fetch_progress_notes(
                start_date, end_date, limit=effective_limit, progress_note_event_type_id=event_type_id, client_service_id=client_service_id
            )
            logger.info(f"ğŸ” [FILTER] connector.fetch_progress_notes ê²°ê³¼ - success={progress_success}, notes_count={len(progress_notes) if progress_notes else 0}")
            
            if not progress_success or not progress_notes:
                error_msg = f"âŒ DB ì§ì ‘ ì ‘ì† ì‹¤íŒ¨: {site} - Progress Notes ì¡°íšŒ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. DB ì—°ê²° ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”."
                logger.error(error_msg)
                raise Exception(error_msg)
            
            return True, progress_notes
            
        except Exception as db_error:
            error_msg = f"âŒ DB ì§ì ‘ ì ‘ì† ì‹¤íŒ¨: {site} - {str(db_error)}. DB ì—°ê²° ì„¤ì • ë° ë“œë¼ì´ë²„ ì„¤ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš”."
            logger.error(error_msg)
            raise Exception(error_msg)
    
    # API ëª¨ë“œ
    try:
        logger.info(f"ğŸŒ API ëª¨ë“œ: Progress Notes ì¡°íšŒ - {site}")
        client = ProgressNoteFetchClient(site)
        logger.info(f"Fetching progress notes for site {site} with {days} days range, event_types: {event_types}")
        
        # ROD ëŒ€ì‹œë³´ë“œìš© íŠ¹ë³„ ì²˜ë¦¬ (yearì™€ monthê°€ ì œê³µë˜ê³  event_typesê°€ nullì´ê±°ë‚˜ ë¹ˆ ë°°ì—´ì¸ ê²½ìš°)
        logger.info(f"Checking ROD mode conditions: year={year}, month={month}, event_types={event_types}, event_types type={type(event_types)}")
        logger.info(f"Condition check: year is not None = {year is not None}, month is not None = {month is not None}")
        logger.info(f"Condition check: not event_types = {not event_types}, len(event_types) == 0 = {len(event_types) == 0 if event_types else 'N/A'}")
        
        # ROD ëª¨ë“œ ì¡°ê±´: yearì™€ monthê°€ ìˆê³ , event_typesê°€ Noneì´ê±°ë‚˜ ë¹ˆ ë°°ì—´ì´ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
        is_rod_mode = (year is not None and 
                      month is not None and 
                      (event_types is None or 
                       len(event_types) == 0 or 
                       (isinstance(event_types, list) and all(not et for et in event_types))))
        
        logger.info(f"ROD mode determination: {is_rod_mode}")
        
        if is_rod_mode:
            logger.info(f"ROD dashboard mode - fetching for year: {year}, month: {month}, event_types: {event_types}")
            return client.fetch_rod_progress_notes(year, month, event_types)
        else:
            # ì¼ë°˜ì ì¸ í”„ë¡œê·¸ë ˆìŠ¤ ë…¸íŠ¸ ìš”ì²­
            # Note: API ëª¨ë“œì—ì„œëŠ” client_service_id í•„í„°ë§ì„ ì§€ì›í•˜ì§€ ì•ŠìŒ
            # í´ë¼ì´ì–¸íŠ¸ í•„í„°ë§ì€ í´ë¼ì´ì–¸íŠ¸ ì¸¡ì—ì„œ ìˆ˜í–‰ë¨
            if event_types:
                # ì´ë²¤íŠ¸ íƒ€ì…ë³„ë¡œ í•„í„°ë§í•˜ì—¬ ê°€ì ¸ì˜¤ê¸°
                logger.info(f"General request with event type filtering: {event_types}")
                return client.fetch_progress_notes_by_event_types(days, event_types)
            else:
                # ì¼ë°˜ í”„ë¡œê·¸ë ˆìŠ¤ ë…¸íŠ¸ ìš”ì²­: ëª¨ë“  ë…¸íŠ¸ ê°€ì ¸ì˜¤ê¸°
                logger.info("No event types specified, fetching all progress notes")
                if client_service_id:
                    logger.warning(f"Client service ID filter ({client_service_id}) is not supported in API mode. Filtering will be done client-side.")
                return client.fetch_recent_progress_notes(days, limit=limit)
    except Exception as e:
        logger.error(f"Error creating client for site {site}: {str(e)}")
        return False, None

def fetch_progress_notes_for_all_sites(days: int = 14) -> Dict[str, tuple[bool, Optional[List[Dict[str, Any]]]]]:
    """
    ëª¨ë“  ì‚¬ì´íŠ¸ì˜ í”„ë¡œê·¸ë ˆìŠ¤ ë…¸íŠ¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
    
    Args:
        days: ê°€ì ¸ì˜¬ ì¼ìˆ˜
        
    Returns:
        ì‚¬ì´íŠ¸ë³„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    results = {}
    
    for site in SITE_SERVERS.keys():
        logger.info(f"Fetching progress notes for site: {site}")
        success, data = fetch_progress_notes_for_site(site, days)
        results[site] = (success, data)
        
        if success:
            logger.info(f"Successfully fetched {len(data) if data else 0} progress notes from {site}")
        else:
            logger.error(f"Failed to fetch progress notes from {site}")
    
    return results

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_progress_note_fetch():
    """í”„ë¡œê·¸ë ˆìŠ¤ ë…¸íŠ¸ ì¡°íšŒ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("=== í”„ë¡œê·¸ë ˆìŠ¤ ë…¸íŠ¸ ì¡°íšŒ í…ŒìŠ¤íŠ¸ ===")
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ì‚¬ì´íŠ¸ ì¶œë ¥
    print(f"Available sites: {list(SITE_SERVERS.keys())}")
    
    # ê° ì‚¬ì´íŠ¸ë³„ë¡œ í…ŒìŠ¤íŠ¸
    for site in SITE_SERVERS.keys():
        print(f"\n--- {site} í…ŒìŠ¤íŠ¸ ---")
        
        try:
            client = ProgressNoteFetchClient(site)
            success, data = client.fetch_recent_progress_notes(days=7)  # 7ì¼ì¹˜ë§Œ í…ŒìŠ¤íŠ¸
            
            if success:
                print(f"âœ… ì„±ê³µ: {len(data) if data else 0}ê°œì˜ í”„ë¡œê·¸ë ˆìŠ¤ ë…¸íŠ¸ ì¡°íšŒ")
                if data and len(data) > 0:
                    # ì²« ë²ˆì§¸ í•­ëª© ìƒ˜í”Œ ì¶œë ¥
                    sample = data[0]
                    print(f"   ìƒ˜í”Œ ë°ì´í„°:")
                    print(f"   - ID: {sample.get('Id')}")
                    print(f"   - ClientId: {sample.get('ClientId')}")
                    print(f"   - EventDate: {sample.get('EventDate')}")
                    print(f"   - Notes: {sample.get('NotesPlainText', '')[:50]}...")
            else:
                print(f"âŒ ì‹¤íŒ¨: í”„ë¡œê·¸ë ˆìŠ¤ ë…¸íŠ¸ ì¡°íšŒ ì‹¤íŒ¨")
                
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {str(e)}")

def fetch_event_types_for_site(site: str) -> tuple[bool, Optional[List[Dict[str, Any]]]]:
    """
    íŠ¹ì • ì‚¬ì´íŠ¸ì˜ ì´ë²¤íŠ¸ íƒ€ì… ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤. (ì‚¬ì´íŠ¸ë³„ JSON íŒŒì¼ ì‚¬ìš©)
    
    Args:
        site (str): ì‚¬ì´íŠ¸ ì´ë¦„
    
    Returns:
        (ì„±ê³µ ì—¬ë¶€, ì´ë²¤íŠ¸ íƒ€ì… ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” None)
    """
    try:
        from api_eventtype import get_site_event_types
        event_types = get_site_event_types(site)
        
        if event_types:
            logger.info(f"Successfully loaded {len(event_types)} event types for site {site}")
            return True, event_types
        else:
            logger.warning(f"No event types found for site {site}")
            return False, None
            
    except Exception as e:
        logger.error(f"Error fetching event types for site {site}: {str(e)}")
        return False, None

# ì‚¬ì´íŠ¸ë³„ Resident of the day ì´ë²¤íŠ¸ íƒ€ì… ID (í•˜ë“œì½”ë”©)
SITE_EVENT_TYPE_IDS = {
    'Parafield Gardens': {'rn_en': 30, 'pca': 121},
    'Nerrilda': {'rn_en': 30, 'pca': 85},
    'Ramsay': {'rn_en': 82, 'pca': 30},
    'West Park': {'rn_en': 30, 'pca': 100},
    'Yankalilla': {'rn_en': 30, 'pca': 63}
}

def find_resident_of_day_event_types(event_types: List[Dict[str, Any]] = None, site: str = None) -> tuple[Optional[int], Optional[int]]:
    """
    ì‚¬ì´íŠ¸ë³„ Resident of the day ì´ë²¤íŠ¸ íƒ€ì… IDë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        event_types: ì´ë²¤íŠ¸ íƒ€ì… ëª©ë¡ (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ, í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€)
        site: ì‚¬ì´íŠ¸ëª… (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ, í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€)
    
    Returns:
        (RN/EN ì´ë²¤íŠ¸ íƒ€ì… ID, PCA ì´ë²¤íŠ¸ íƒ€ì… ID)
    """
    # í˜„ì¬ ì‚¬ì´íŠ¸ì˜ ì´ë²¤íŠ¸ íƒ€ì… ID ë°˜í™˜ (í•˜ë“œì½”ë”©ëœ ê°’ ì‚¬ìš©)
    # ì‚¬ì´íŠ¸ëŠ” ProgressNoteFetchClientì˜ self.siteì—ì„œ ê°€ì ¸ì˜´
    return None, None  # ì´ í•¨ìˆ˜ëŠ” ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ

def get_site_event_type_ids(site: str) -> tuple[Optional[int], Optional[int]]:
    """
    íŠ¹ì • ì‚¬ì´íŠ¸ì˜ Resident of the day ì´ë²¤íŠ¸ íƒ€ì… IDë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        site: ì‚¬ì´íŠ¸ëª…
    
    Returns:
        (RN/EN ì´ë²¤íŠ¸ íƒ€ì… ID, PCA ì´ë²¤íŠ¸ íƒ€ì… ID)
    """
    site_ids = SITE_EVENT_TYPE_IDS.get(site)
    if site_ids:
        rn_en_id = site_ids.get('rn_en')
        pca_id = site_ids.get('pca')
        logger.info(f"Using hardcoded event type IDs for {site}: RN/EN={rn_en_id}, PCA={pca_id}")
        return rn_en_id, pca_id
    else:
        logger.error(f"No event type IDs found for site: {site}")
        return None, None

# ê¸°ì¡´ APIì—ì„œ ì´ë²¤íŠ¸ íƒ€ì…ì„ ê°€ì ¸ì˜¤ëŠ” ë¡œì§ (ì£¼ì„ ì²˜ë¦¬)
"""
def find_resident_of_day_event_types_from_api(event_types: List[Dict[str, Any]]) -> tuple[Optional[int], Optional[int]]:
    # ì´ë²¤íŠ¸ íƒ€ì… ëª©ë¡ì—ì„œ Resident of the day ê´€ë ¨ ì´ë²¤íŠ¸ íƒ€ì… IDë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    rn_en_id = None
    pca_id = None
    
    for event_type in event_types:
        description = event_type.get('Description', '').lower()
        event_id = event_type.get('Id')
        
        if 'resident of the day' in description:
            # lifestyleì€ ì œì™¸
            if 'lifestyle' in description:
                logger.info(f"Skipping lifestyle event type: ID {event_id} - {event_type.get('Description')}")
                continue
            elif 'pca' in description:
                pca_id = event_id
                logger.info(f"Found PCA Resident of the day event type: ID {event_id} - {event_type.get('Description')}")
            elif any(keyword in description for keyword in ['rn', 'en', 'nurse']):
                rn_en_id = event_id
                logger.info(f"Found RN/EN Resident of the day event type: ID {event_id} - {event_type.get('Description')}")
    
    return rn_en_id, pca_id
"""

def fetch_residence_of_day_notes_with_client_data(site, year, month):
    """
    íŠ¹ì • ë…„ì›”ì˜ "Resident of the day" ë…¸íŠ¸ë¥¼ í´ë¼ì´ì–¸íŠ¸ ë°ì´í„°ì™€ í•¨ê»˜ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    Args:
        site (str): ì‚¬ì´íŠ¸ ì´ë¦„
        year (int): ë…„ë„
        month (int): ì›”
    
    Returns:
        dict: Residenceë³„ ìƒíƒœ ì •ë³´
    """
    try:
        logger.info(f"Fetching Resident of the day notes for {site} - {year}/{month}")
        
        # Create debug info for file logging
        debug_info = {
            'timestamp': datetime.now().isoformat(),
            'site': site,
            'year': year,
            'month': month,
            'steps': []
        }
        
        # 1. í´ë¼ì´ì–¸íŠ¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        from api_client import fetch_client_information
        client_success, client_data = fetch_client_information(site)
        if not client_success or not client_data:
            logger.error(f"Failed to fetch client data for {site}")
            return {}
        
        debug_info['steps'].append({
            'step': 'client_data_fetch',
            'success': client_success,
            'client_count': len(client_data) if client_data else 0,
            'sample_clients': []
        })
        
        # Add sample client data to debug info
        if client_data:
            for i, client in enumerate(client_data[:3]):
                first_name = client.get('FirstName', '')
                surname = client.get('Surname', '')
                last_name = client.get('LastName', '')
                main_id = client.get('MainClientServiceId', '')
                debug_info['steps'][-1]['sample_clients'].append({
                    'index': i+1,
                    'name': f"{first_name} {surname or last_name}",
                    'main_client_service_id': main_id
                })
        
        # 2. ë‚ ì§œ ë²”ìœ„ ì„¤ì •
        start_date = datetime(year, month, 1)
        if month == 12:
            end_date = datetime(year + 1, 1, 1)
        else:
            end_date = datetime(year, month + 1, 1)
        
        debug_info['steps'].append({
            'step': 'date_range_setup',
            'start_date': start_date.isoformat(),
            'end_date': end_date.isoformat()
        })
        
        # 3. ì‚¬ì´íŠ¸ë³„ Resident of the day ê´€ë ¨ EventType IDë“¤ ê°€ì ¸ì˜¤ê¸° (í•˜ë“œì½”ë”©)
        rn_en_id, pca_id = get_site_event_type_ids(site)
        
        # ê¸°ì¡´ APIì—ì„œ ì´ë²¤íŠ¸ íƒ€ì…ì„ ê°€ì ¸ì˜¤ëŠ” ë¡œì§ (ì£¼ì„ ì²˜ë¦¬)
        # event_success, event_types = fetch_event_types_for_site(site)
        # if not event_success or not event_types:
        #     logger.error(f"Failed to fetch event types for {site}")
        #     return {}
        # rn_en_id, pca_id = find_resident_of_day_event_types(event_types)
        
        debug_info['steps'].append({
            'step': 'event_type_fetch',
            'success': True,  # í•˜ë“œì½”ë”©ëœ ê°’ ì‚¬ìš©
            'event_types_count': 0,  # APIì—ì„œ ê°€ì ¸ì˜¤ì§€ ì•ŠìŒ
            'rn_en_id': rn_en_id,
            'pca_id': pca_id
        })
        
        if not rn_en_id and not pca_id:
            logger.warning(f"No Resident of the day event types found for {site}")
            return {}
        
        # 4. ëª¨ë“  Resident of the day ë…¸íŠ¸ë¥¼ í•œ ë²ˆì— ê°€ì ¸ì˜¤ê¸° (ìµœì í™”)
        all_resident_notes = []
        event_type_mapping = {}  # ë…¸íŠ¸ë¥¼ RN/ENê³¼ PCAë¡œ ë¶„ë¥˜í•˜ê¸° ìœ„í•œ ë§¤í•‘
        rn_en_notes = []  # RN/EN ë…¸íŠ¸ë§Œ ë”°ë¡œ ì €ì¥
        pca_notes = []    # PCA ë…¸íŠ¸ë§Œ ë”°ë¡œ ì €ì¥
        
        # ë¨¼ì € ì €ì¥ëœ íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ì°¾ì•„ë³´ê¸°
        logs_dir = os.path.join(os.getcwd(), 'data')
        timestamp_pattern = f"{year}_{month:02d}"
        
        # 5ì›” ë°ì´í„° íŒŒì¼ ì°¾ê¸° (ì •í™•í•œ íŒ¨í„´ ë§¤ì¹­)
        rn_en_files = [f for f in os.listdir(logs_dir) if f.startswith(f'progress_notes_rn_en_{site}_{timestamp_pattern}_')]
        pca_files = [f for f in os.listdir(logs_dir) if f.startswith(f'progress_notes_pca_{site}_{timestamp_pattern}_')]
        
        logger.info(f"Looking for files with pattern: {timestamp_pattern}")
        logger.info(f"Site: {site}")
        logger.info(f"All files in data directory: {[f for f in os.listdir(logs_dir) if 'Parafield' in f and '2025_05' in f]}")
        logger.info(f"Found RN/EN files: {rn_en_files}")
        logger.info(f"Found PCA files: {pca_files}")
        
        if rn_en_files and pca_files:
            # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì„ íƒ
            rn_en_files.sort(reverse=True)
            pca_files.sort(reverse=True)
            
            try:
                # RN/EN ë…¸íŠ¸ ë¡œë“œ
                rn_en_filepath = os.path.join(logs_dir, rn_en_files[0])
                with open(rn_en_filepath, 'r', encoding='utf-8') as f:
                    rn_en_notes = json.load(f)
                logger.info(f"Loaded {len(rn_en_notes)} RN/EN notes from file: {rn_en_files[0]}")
                
                # PCA ë…¸íŠ¸ ë¡œë“œ
                pca_filepath = os.path.join(logs_dir, pca_files[0])
                with open(pca_filepath, 'r', encoding='utf-8') as f:
                    pca_notes = json.load(f)
                logger.info(f"Loaded {len(pca_notes)} PCA notes from file: {pca_files[0]}")
                
                # ëª¨ë“  ë…¸íŠ¸ í•©ì¹˜ê¸°
                all_resident_notes = rn_en_notes + pca_notes
                
                # ë…¸íŠ¸ë¥¼ íƒ€ì…ë³„ë¡œ ë¶„ë¥˜
                for note in rn_en_notes:
                    event_type_mapping[note.get('Id')] = "RN/EN"
                for note in pca_notes:
                    event_type_mapping[note.get('Id')] = "PCA"
                
                logger.info(f"Successfully loaded {len(all_resident_notes)} notes from saved files")
                
            except Exception as e:
                logger.error(f"Failed to load notes from files: {str(e)}")
                # íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ì‹œ APIì—ì„œ ê°€ì ¸ì˜¤ê¸°
                all_resident_notes = []
                rn_en_notes = []
                pca_notes = []
        else:
            logger.info(f"No saved files found for {site} {year}/{month}, fetching from API")
        
        # ì €ì¥ëœ íŒŒì¼ì´ ì—†ê±°ë‚˜ ë¡œë“œ ì‹¤íŒ¨í•œ ê²½ìš° APIì—ì„œ ê°€ì ¸ì˜¤ê¸°
        if not all_resident_notes:
            # RN/EN, PCA ì´ë²¤íŠ¸ íƒ€ì… IDë¥¼ í¬í•¨í•˜ì—¬ í•œ ë²ˆì— ê°€ì ¸ì˜¤ê¸°
            event_type_ids = []
            if rn_en_id:
                event_type_ids.append(rn_en_id)
            if pca_id:
                event_type_ids.append(pca_id)
            
            if event_type_ids:
                # ëª¨ë“  ì´ë²¤íŠ¸ íƒ€ì…ì„ í•œ ë²ˆì— ê°€ì ¸ì˜¤ê¸°
                client = ProgressNoteFetchClient(site)
            
            # ë‚ ì§œ ë²”ìœ„ë¥¼ ì¡°ê¸ˆ ë” ë„“ê²Œ ì„¤ì • (ì „í›„ 1ì¼ í¬í•¨)
            extended_start_date = start_date - timedelta(days=1)
            extended_end_date = end_date + timedelta(days=1)
            
            debug_info['steps'].append({
                'step': 'fetch_notes_optimized',
                'event_type_ids': event_type_ids,
                'date_range': f"{extended_start_date.isoformat()} to {extended_end_date.isoformat()}",
                'notes_fetched': 0
            })
            
            # ê° ì´ë²¤íŠ¸ íƒ€ì…ë³„ë¡œ ê°œë³„ í˜¸ì¶œ (APIê°€ OR ì¡°ê±´ì„ ì§€ì›í•˜ì§€ ì•ŠëŠ” ê²½ìš°)
            for event_type_id in event_type_ids:
                success, notes = client.fetch_progress_notes(
                    start_date=extended_start_date,
                    end_date=extended_end_date,
                    limit=None,  # ì œí•œ ì—†ìŒ
                    progress_note_event_type_id=event_type_id
                )
                
                if success and notes is not None:
                    all_resident_notes.extend(notes)
                    
                    # ë…¸íŠ¸ë¥¼ íƒ€ì…ë³„ë¡œ ë¶„ë¥˜
                    if event_type_id == rn_en_id:
                        event_type_name = "RN/EN"
                    elif event_type_id == pca_id:
                        event_type_name = "PCA"
                    else:
                        event_type_name = "Unknown"
                    
                    for note in notes:
                        event_type_mapping[note.get('Id')] = event_type_name
                    
                    # Event Typeë³„ë¡œ ë…¸íŠ¸ ë¶„ë¦¬ ì €ì¥
                    if event_type_name == "RN/EN":
                        rn_en_notes = notes
                    elif event_type_name == "PCA":
                        pca_notes = notes
                    
                    debug_info['steps'][-1]['notes_fetched'] += len(notes)
                    logger.info(f"Fetched {len(notes)} notes for event type ID {event_type_id} ({event_type_name})")
                else:
                    logger.warning(f"No notes found for EventType ID {event_type_id}")
        else:
            logger.warning("No Resident of the day event types found")
        
        # Progress Noteë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥ (Event Typeë³„ë¡œ ë¶„ë¦¬)
        try:
            logs_dir = os.path.join(os.getcwd(), 'data')
            os.makedirs(logs_dir, exist_ok=True)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # RN/EN ë…¸íŠ¸ ì €ì¥
            if rn_en_notes:
                rn_en_filename = f'progress_notes_rn_en_{site}_{year}_{month:02d}_{timestamp}.json'
                rn_en_filepath = os.path.join(logs_dir, rn_en_filename)
                with open(rn_en_filepath, 'w', encoding='utf-8') as f:
                    json.dump(rn_en_notes, f, indent=2, ensure_ascii=False)
                logger.info(f"RN/EN notes saved to: {rn_en_filename}")
            
            # PCA ë…¸íŠ¸ ì €ì¥
            if pca_notes:
                pca_filename = f'progress_notes_pca_{site}_{year}_{month:02d}_{timestamp}.json'
                pca_filepath = os.path.join(logs_dir, pca_filename)
                with open(pca_filepath, 'w', encoding='utf-8') as f:
                    json.dump(pca_notes, f, indent=2, ensure_ascii=False)
                logger.info(f"PCA notes saved to: {pca_filename}")
                
        except Exception as e:
            logger.error(f"Failed to save progress notes to JSON files: {str(e)}")
        
        debug_info['steps'].append({
            'step': 'total_notes_summary',
            'total_notes': len(all_resident_notes),
            'sample_notes': []
        })
        
        # Add sample notes to debug info
        if all_resident_notes:
            for i, note in enumerate(all_resident_notes[:3]):
                debug_info['steps'][-1]['sample_notes'].append({
                    'index': i+1,
                    'id': note.get('Id'),
                    'client_service_id': note.get('ClientServiceId'),
                    'event_type': note.get('ProgressNoteEventType', {}).get('Description', 'N/A'),
                    'event_date': note.get('EventDate', 'N/A')
                })
        
        # 5. Residenceë³„ë¡œ ë…¸íŠ¸ ë§¤ì¹­ ë° ìƒíƒœ ìƒì„±
        residence_status = {}
        unmatched_notes = []  # ë§¤ì¹­ ì‹¤íŒ¨í•œ ë…¸íŠ¸ ì¶”ì 
        
        # í´ë¼ì´ì–¸íŠ¸ ë°ì´í„° êµ¬ì¡° í™•ì¸ ë° ì²˜ë¦¬
        if isinstance(client_data, dict):
            client_list = list(client_data.values()) if client_data else []
        elif isinstance(client_data, list):
            client_list = client_data
        else:
            logger.error(f"Unexpected client data type: {type(client_data)}")
            client_list = []
        
        logger.info(f"Processing {len(client_list)} clients")
        
        # ë¨¼ì € ëª¨ë“  residenceì˜ ClientRecordIdë¥¼ ìˆ˜ì§‘
        residence_client_mapping = {}
        for residence in client_list:
            if isinstance(residence, dict):
                first_name = residence.get('FirstName', '')
                surname = residence.get('Surname', '')
                last_name = residence.get('LastName', '')
                preferred_name = residence.get('PreferredName', '')
                wing_name = residence.get('WingName', '')
                
                # Residence ì´ë¦„ ìƒì„± - FirstNameê³¼ Surname/LastName ì¡°í•©
                if first_name and surname:
                    residence_name = f"{first_name} {surname}"
                elif first_name and last_name:
                    residence_name = f"{first_name} {last_name}"
                elif first_name:
                    residence_name = first_name
                else:
                    continue
                
                # Residenceì˜ ClientRecordId ì°¾ê¸° (ì‹¤ì‹œê°„ API ë°ì´í„°ì—ì„œëŠ” ë‹¤ë¥¸ í•„ë“œëª… ì‚¬ìš©)
                residence_client_record_id = residence.get('ClientRecordId') or residence.get('Id') or residence.get('ClientId')
                
                # Residence ì´ë¦„ê³¼ ClientRecordId ë§¤í•‘ ì €ì¥
                residence_client_mapping[residence_name] = residence_client_record_id
                
                # ëª¨ë“  residentë¥¼ í™”ë©´ì— í‘œì‹œ (ë…¸íŠ¸ê°€ ì—†ì–´ë„ í‘œì‹œ)
                residence_notes = []
                
                if residence_client_record_id:
                    # í•´ë‹¹ Residenceì˜ ë…¸íŠ¸ ì°¾ê¸° (ë§¤ì¹­ëœ ë…¸íŠ¸ë§Œ)
                    for note in all_resident_notes:
                        note_client_id = note.get('ClientId')
                        
                        # ë§¤ì¹­ ë¡œì§: ClientRecordIdë¡œë§Œ ë§¤ì¹­
                        if note_client_id == residence_client_record_id:
                            residence_notes.append(note)
                
                # ë…¸íŠ¸ê°€ ì—†ì–´ë„ residence_statusì— ì¶”ê°€ (ëª¨ë“  residence í‘œì‹œ)
                

                
                # Residenceë³„ ìƒíƒœ ìƒì„± (ë…¸íŠ¸ê°€ ì—†ì–´ë„ ìƒì„±)
                rn_en_has_note = False
                pca_has_note = False
                rn_en_count = 0
                pca_count = 0
                
                for note in residence_notes:
                    note_id = note.get('Id')
                    event_type_name = event_type_mapping.get(note_id)
                    
                    if event_type_name == "RN/EN":
                        rn_en_has_note = True
                        rn_en_count += 1
                    elif event_type_name == "PCA":
                        pca_has_note = True
                        pca_count += 1
                
                residence_status[residence_name] = {
                    'residence_name': residence_name,
                    'preferred_name': preferred_name,
                    'wing_name': wing_name,
                    'rn_en_has_note': rn_en_has_note,
                    'pca_has_note': pca_has_note,
                    'rn_en_count': rn_en_count,
                    'pca_count': pca_count,
                    'total_count': rn_en_count + pca_count
                }
        
        # ë§¤ì¹­ë˜ì§€ ì•Šì€ ë…¸íŠ¸ ê³„ì‚° (íš¨ìœ¨ì ì¸ ë°©ë²•)
        matched_note_ids = set()
        
        logger.info(f"Total notes to process: {len(all_resident_notes)}")
        logger.info(f"Total residences available: {len(residence_client_mapping)}")
        
        # ê° ë…¸íŠ¸ê°€ ì–´ë–¤ residenceì™€ ë§¤ì¹­ë˜ëŠ”ì§€ í™•ì¸
        for note in all_resident_notes:
            note_client_id = note.get('ClientId')
            note_matched = False
            
            # ëª¨ë“  residenceì˜ ClientRecordIdì™€ ë¹„êµ
            for residence_name, residence_client_record_id in residence_client_mapping.items():
                if residence_client_record_id and note_client_id == residence_client_record_id:
                    matched_note_ids.add(note.get('Id'))
                    note_matched = True
                    break
            
            # ë§¤ì¹­ë˜ì§€ ì•Šì€ ë…¸íŠ¸ ì¶”ê°€
            if not note_matched:
                unmatched_note_info = {
                    'note_id': note.get('Id'),
                    'client_id': note_client_id,
                    'event_type': note.get('ProgressNoteEventType', {}).get('Description', 'Unknown'),
                    'event_date': note.get('EventDate', 'Unknown'),
                    'residence_name': 'Unknown',
                    'residence_client_record_id': 'Unknown'
                }
                unmatched_notes.append(unmatched_note_info)
        
        logger.info(f"Matched notes: {len(matched_note_ids)}")
        logger.info(f"Unmatched notes: {len(unmatched_notes)}")
        
        # Save debug info to file
        try:
            logs_dir = os.path.join(os.getcwd(), 'logs')
            os.makedirs(logs_dir, exist_ok=True)
            timestamp = datetime.now().strftime('%Y-%m-%d_%H%M%S')
            filename = f'rod_processing_{site}_{year}_{month:02d}_{timestamp}.json'
            filepath = os.path.join(logs_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(debug_info, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"Failed to save ROD processing debug log: {str(e)}")
        
        # ë§¤ì¹­ ì‹¤íŒ¨í•œ ë…¸íŠ¸ ì¤‘ë³µ ì œê±°
        unique_unmatched_notes = []
        seen_notes = set()
        for note in unmatched_notes:
            note_key = f"{note['note_id']}_{note['client_id']}"
            if note_key not in seen_notes:
                unique_unmatched_notes.append(note)
                seen_notes.add(note_key)
        
        # ë§¤ì¹­ë˜ì§€ ì•Šì€ ë…¸íŠ¸ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        if unique_unmatched_notes:
            try:
                logs_dir = os.path.join(os.getcwd(), 'data')
                os.makedirs(logs_dir, exist_ok=True)
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                
                unmatched_filename = f'unmatched_notes_{site}_{year}_{month:02d}_{timestamp}.json'
                unmatched_filepath = os.path.join(logs_dir, unmatched_filename)
                
                unmatched_data = {
                    'site': site,
                    'year': year,
                    'month': month,
                    'timestamp': datetime.now().isoformat(),
                    'total_notes': len(all_resident_notes),
                    'matched_notes': len(matched_note_ids),
                    'unmatched_notes_count': len(unique_unmatched_notes),
                    'unmatched_notes': unique_unmatched_notes,
                    'summary': {
                        'total_residences': len(residence_client_mapping),
                        'available_client_ids': list(residence_client_mapping.values()),
                        'unmatched_client_ids': list(set([note['client_id'] for note in unique_unmatched_notes]))
                    }
                }
                
                with open(unmatched_filepath, 'w', encoding='utf-8') as f:
                    json.dump(unmatched_data, f, indent=2, ensure_ascii=False)
                
                logger.info(f"Saved {len(unique_unmatched_notes)} unmatched notes to: {unmatched_filename}")
                
            except Exception as e:
                logger.error(f"Failed to save unmatched notes to file: {str(e)}")
        else:
            logger.info("No unmatched notes found")
        
        logger.info(f"ROD processing completed for {site}: {len(residence_status)} residences, {len(unique_unmatched_notes)} unmatched notes")
        if len(residence_status) == 0:
            logger.warning("No residences found in residence_status!")
        
        # residence_statusì— unmatched_notes ì •ë³´ ì¶”ê°€
        result = {
            'residence_status': residence_status,
            'unmatched_notes': unique_unmatched_notes
        }
        return result
        
    except Exception as e:
        logger.error(f"Error in fetch_residence_of_day_notes_with_client_data: {str(e)}")
        return {}

def save_data_to_file(site: str, year: int, month: int, all_notes: list, residence_status: dict, debug_info: dict = None):
    """
    ë°›ì€ ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        site (str): ì‚¬ì´íŠ¸ ì´ë¦„
        year (int): ë…„ë„
        month (int): ì›”
        all_notes (list): ëª¨ë“  Progress Note ë°ì´í„°
        residence_status (dict): Residenceë³„ ìƒíƒœ ì •ë³´
        debug_info (dict): ë””ë²„ê¹… ì •ë³´ (ì„ íƒì‚¬í•­)
    """
    try:
        # íŒŒì¼ëª… ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{site}_{year:04d}{month:02d}_{timestamp}.json"
        filepath = os.path.join('data', filename)
        
        # data ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
        os.makedirs('data', exist_ok=True)
        
        # JSON ë°ì´í„° êµ¬ì„±
        data_to_save = {
            'site': site,
            'year': year,
            'month': month,
            'timestamp': timestamp,
            'raw_progress_notes': all_notes,
            'processed_residence_status': residence_status
        }
        
        # ë””ë²„ê¹… ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if debug_info:
            data_to_save['debug_info'] = debug_info
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data_to_save, f, indent=2, ensure_ascii=False)
        
        logger.info(f"Data saved to file: {filepath}")
        
    except Exception as e:
        logger.error(f"Error saving data to file: {str(e)}")

def fetch_residence_of_day_notes(site: str, start_date: datetime, end_date: datetime) -> tuple[bool, Optional[Dict[str, List[Dict[str, Any]]]]]:
    """
    íŠ¹ì • ì‚¬ì´íŠ¸ì—ì„œ "Resident of the day" ì œëª©ì˜ ë…¸íŠ¸ë¥¼ Residenceë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    Args:
        site: ì‚¬ì´íŠ¸ëª…
        start_date: ì‹œì‘ ë‚ ì§œ
        end_date: ì¢…ë£Œ ë‚ ì§œ
        
    Returns:
        (ì„±ê³µ ì—¬ë¶€, Residenceë³„ ë…¸íŠ¸ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None)
    """
    try:
        client = ProgressNoteFetchClient(site)
        success, all_notes = client.fetch_progress_notes(start_date, end_date, limit=1000)
        
        if not success or not all_notes:
            logger.warning(f"No progress notes found for site {site}")
            return True, {}
        
        # "Resident of the day" ì œëª©ì„ ê°€ì§„ ë…¸íŠ¸ í•„í„°ë§ ë° Residenceë³„ ê·¸ë£¹í™”
        resident_notes = {}
        for note in all_notes:
            # NotesDetailTitleì´ "Resident of the day"ì¸ì§€ í™•ì¸
            if note.get('NotesDetailTitle') and 'resident of the day' in note['NotesDetailTitle'].lower():
                # Residence ì´ë¦„ ì¶”ì¶œ (NotesDetailTitleì—ì„œ "Resident of the day - [Residence Name]" í˜•ì‹)
                title = note.get('NotesDetailTitle', '')
                residence_name = extract_residence_name_from_title(title)
                
                if residence_name:
                    if residence_name not in resident_notes:
                        resident_notes[residence_name] = []
                    resident_notes[residence_name].append(note)
        
        logger.info(f"Found Resident of the day notes for {len(resident_notes)} residences in site {site}")
        return True, resident_notes
        
    except Exception as e:
        logger.error(f"Error fetching Resident of the day notes for site {site}: {str(e)}")
        return False, None

def extract_residence_name_from_title(title: str) -> Optional[str]:
    """
    NotesDetailTitleì—ì„œ Residence ì´ë¦„ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        title: NotesDetailTitle ë¬¸ìì—´
        
    Returns:
        Residence ì´ë¦„ ë˜ëŠ” None
    """
    try:
        # "Resident of the day - [Residence Name]" í˜•ì‹ì—ì„œ Residence ì´ë¦„ ì¶”ì¶œ
        if 'resident of the day' in title.lower():
            # ëŒ€ì‹œ(-) ì´í›„ì˜ í…ìŠ¤íŠ¸ë¥¼ Residence ì´ë¦„ìœ¼ë¡œ ê°„ì£¼
            parts = title.split('-')
            if len(parts) > 1:
                residence_name = parts[1].strip()
                return residence_name if residence_name else None
        
        # ë‹¤ë¥¸ í˜•ì‹ë„ ì‹œë„
        if 'resident of the day' in title.lower():
            # "Resident of the day [Residence Name]" í˜•ì‹
            import re
            match = re.search(r'resident of the day\s*[-:]\s*(.+)', title, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        return None
    except Exception as e:
        logger.error(f"Error extracting residence name from title '{title}': {str(e)}")
        return None

def fetch_residence_of_day_notes_for_all_sites(start_date: datetime, end_date: datetime) -> Dict[str, tuple[bool, Optional[List[Dict[str, Any]]]]]:
    """
    ëª¨ë“  ì‚¬ì´íŠ¸ì—ì„œ "Resident of the day" ë…¸íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    Args:
        start_date: ì‹œì‘ ë‚ ì§œ
        end_date: ì¢…ë£Œ ë‚ ì§œ
        
    Returns:
        ì‚¬ì´íŠ¸ë³„ (ì„±ê³µ ì—¬ë¶€, Resident of the day ë…¸íŠ¸ ë¦¬ìŠ¤íŠ¸) ë”•ì…”ë„ˆë¦¬
    """
    results = {}
    
    for site in SITE_SERVERS.keys():
        try:
            success, data = fetch_residence_of_day_notes(site, start_date, end_date)
            results[site] = (success, data)
            logger.info(f"Site {site}: {'Success' if success else 'Failed'} - {len(data) if data else 0} Resident of the day notes")
        except Exception as e:
            logger.error(f"Error fetching Resident of the day data for site {site}: {str(e)}")
            results[site] = (False, None)
    
    return results

if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_progress_note_fetch() 