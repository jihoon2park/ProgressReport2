#!/usr/bin/env python3
"""
Progress Report System - SQLite ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ
ì „ì²´ JSON ë°ì´í„°ë¥¼ SQLiteë¡œ ë‹¨ê³„ë³„ ë§ˆì´ê·¸ë ˆì´ì…˜
"""

import sqlite3
import json
import os
from datetime import datetime
from typing import Dict, List, Any
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ProgressReportMigration:
    def __init__(self, db_path: str = 'progress_report.db'):
        self.db_path = db_path
        self.conn = None
        
    def connect(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
        self.conn = sqlite3.connect(self.db_path)
        self.conn.row_factory = sqlite3.Row
        return self.conn
    
    def close(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ"""
        if self.conn:
            self.conn.close()

    # ===========================================
    # PHASE 1: í•µì‹¬ ì˜êµ¬ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
    # ===========================================
    
    def phase1_migrate_core_data(self):
        """Phase 1: ì‚¬ìš©ì, FCM í† í°, ë¡œê·¸ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜"""
        logger.info("=== Phase 1: í•µì‹¬ ì˜êµ¬ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘ ===")
        
        # 1-1. ì‚¬ìš©ì ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
        self.migrate_users()
        
        # 1-2. FCM í† í° ë§ˆì´ê·¸ë ˆì´ì…˜
        self.migrate_fcm_tokens()
        
        # 1-3. ì‚¬ìš© ë¡œê·¸ ë§ˆì´ê·¸ë ˆì´ì…˜
        self.migrate_usage_logs()
        
        logger.info("=== Phase 1 ì™„ë£Œ ===")
    
    def migrate_users(self):
        """config_users.pyì—ì„œ ì‚¬ìš©ì ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜"""
        logger.info("ì‚¬ìš©ì ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
        
        # config_users.pyì—ì„œ USERS_DB ê°€ì ¸ì˜¤ê¸°
        try:
            from config_users import USERS_DB
            
            cursor = self.conn.cursor()
            
            for username, user_data in USERS_DB.items():
                cursor.execute('''
                    INSERT OR REPLACE INTO users 
                    (username, password_hash, first_name, last_name, role, position, location)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (
                    username,
                    user_data['password_hash'],
                    user_data['first_name'],
                    user_data['last_name'],
                    user_data['role'],
                    user_data['position'],
                    json.dumps(user_data.get('location', []))
                ))
            
            self.conn.commit()
            logger.info(f"ì‚¬ìš©ì {len(USERS_DB)}ëª… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ì‚¬ìš©ì ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
    
    def migrate_fcm_tokens(self):
        """credential/fcm_tokens.json ë§ˆì´ê·¸ë ˆì´ì…˜"""
        logger.info("FCM í† í° ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
        
        try:
            with open('credential/fcm_tokens.json', 'r') as f:
                fcm_data = json.load(f)
            
            cursor = self.conn.cursor()
            
            for user_id, tokens in fcm_data.items():
                if isinstance(tokens, list):
                    for token_info in tokens:
                        cursor.execute('''
                            INSERT OR REPLACE INTO fcm_tokens 
                            (user_id, token, device_info, created_at, last_used, is_active)
                            VALUES (?, ?, ?, ?, ?, ?)
                        ''', (
                            token_info.get('user_id', user_id),
                            token_info.get('token', ''),
                            token_info.get('device_info', ''),
                            token_info.get('created_at'),
                            token_info.get('last_used'),
                            token_info.get('is_active', True)
                        ))
            
            self.conn.commit()
            logger.info("FCM í† í° ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
            
        except FileNotFoundError:
            logger.warning("FCM í† í° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            logger.error(f"FCM í† í° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
    
    def migrate_usage_logs(self):
        """UsageLog í´ë”ì˜ ëª¨ë“  ë¡œê·¸ íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜"""
        logger.info("ì‚¬ìš© ë¡œê·¸ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
        
        usage_log_dir = 'UsageLog'
        if not os.path.exists(usage_log_dir):
            logger.warning("UsageLog ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        cursor = self.conn.cursor()
        access_count = 0
        progress_count = 0
        
        # ì—°ë„/ì›” í´ë” ìˆœíšŒ
        for year_month in os.listdir(usage_log_dir):
            year_month_path = os.path.join(usage_log_dir, year_month)
            if not os.path.isdir(year_month_path):
                continue
            
            for log_file in os.listdir(year_month_path):
                log_path = os.path.join(year_month_path, log_file)
                
                try:
                    with open(log_path, 'r') as f:
                        log_data = json.load(f)
                    
                    if 'access_' in log_file:
                        # ì ‘ê·¼ ë¡œê·¸ ë§ˆì´ê·¸ë ˆì´ì…˜
                        for entry in log_data:
                            user_info = entry.get('user', {})
                            cursor.execute('''
                                INSERT INTO access_logs 
                                (timestamp, username, display_name, role, position, page_accessed)
                                VALUES (?, ?, ?, ?, ?, ?)
                            ''', (
                                entry.get('timestamp'),
                                user_info.get('username'),
                                user_info.get('display_name'),
                                user_info.get('role'),
                                user_info.get('position'),
                                entry.get('page', 'unknown')
                            ))
                            access_count += 1
                    
                    elif 'progress_notes_' in log_file:
                        # Progress Note ë¡œê·¸ ë§ˆì´ê·¸ë ˆì´ì…˜
                        for entry in log_data:
                            user_info = entry.get('user', {})
                            cursor.execute('''
                                INSERT INTO progress_note_logs 
                                (timestamp, username, display_name, role, position, 
                                 client_name, note_content, site)
                                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                            ''', (
                                entry.get('timestamp'),
                                user_info.get('username'),
                                user_info.get('display_name'),
                                user_info.get('role'),
                                user_info.get('position'),
                                entry.get('client_name'),
                                entry.get('note_content'),
                                entry.get('site')
                            ))
                            progress_count += 1
                
                except Exception as e:
                    logger.error(f"ë¡œê·¸ íŒŒì¼ {log_path} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        
        self.conn.commit()
        logger.info(f"ì ‘ê·¼ ë¡œê·¸ {access_count}ê°œ, Progress Note ë¡œê·¸ {progress_count}ê°œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")

    # ===========================================
    # PHASE 2: ì°¸ì¡° ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
    # ===========================================
    
    def phase2_migrate_reference_data(self):
        """Phase 2: ì¼€ì–´ ì˜ì—­, ì´ë²¤íŠ¸ íƒ€ì… ë§ˆì´ê·¸ë ˆì´ì…˜"""
        logger.info("=== Phase 2: ì°¸ì¡° ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘ ===")
        
        # 2-1. ì¼€ì–´ ì˜ì—­ ë§ˆì´ê·¸ë ˆì´ì…˜
        self.migrate_care_areas()
        
        # 2-2. ì´ë²¤íŠ¸ íƒ€ì… ë§ˆì´ê·¸ë ˆì´ì…˜
        self.migrate_event_types()
        
        logger.info("=== Phase 2 ì™„ë£Œ ===")
    
    def migrate_care_areas(self):
        """data/carearea.json ë§ˆì´ê·¸ë ˆì´ì…˜"""
        logger.info("ì¼€ì–´ ì˜ì—­ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
        
        try:
            with open('data/carearea.json', 'r') as f:
                care_areas = json.load(f)
            
            cursor = self.conn.cursor()
            
            for area in care_areas:
                cursor.execute('''
                    INSERT OR REPLACE INTO care_areas 
                    (id, description, is_archived, is_external, last_updated_date)
                    VALUES (?, ?, ?, ?, ?)
                ''', (
                    area['Id'],
                    area['Description'],
                    area.get('IsArchived', False),
                    area.get('IsExternal', False),
                    area.get('LastUpdatedDate')
                ))
            
            self.conn.commit()
            logger.info(f"ì¼€ì–´ ì˜ì—­ {len(care_areas)}ê°œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ì¼€ì–´ ì˜ì—­ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
    
    def migrate_event_types(self):
        """data/eventtype.json ë§ˆì´ê·¸ë ˆì´ì…˜"""
        logger.info("ì´ë²¤íŠ¸ íƒ€ì… ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
        
        try:
            with open('data/eventtype.json', 'r') as f:
                event_types = json.load(f)
            
            cursor = self.conn.cursor()
            
            for event in event_types:
                cursor.execute('''
                    INSERT OR REPLACE INTO event_types 
                    (id, description, color_argb, is_archived, is_external, last_updated_date)
                    VALUES (?, ?, ?, ?, ?, ?)
                ''', (
                    event['Id'],
                    event['Description'],
                    event.get('ColorArgb'),
                    event.get('IsArchived', False),
                    event.get('IsExternal', False),
                    event.get('LastUpdatedDate')
                ))
            
            self.conn.commit()
            logger.info(f"ì´ë²¤íŠ¸ íƒ€ì… {len(event_types)}ê°œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ì´ë²¤íŠ¸ íƒ€ì… ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")

    # ===========================================
    # PHASE 3: í´ë¼ì´ì–¸íŠ¸ ë°ì´í„° ìºì‹œí™”
    # ===========================================
    
    def phase3_migrate_client_data(self):
        """Phase 3: í´ë¼ì´ì–¸íŠ¸ ë°ì´í„° ìºì‹œ í…Œì´ë¸” êµ¬ì¶•"""
        logger.info("=== Phase 3: í´ë¼ì´ì–¸íŠ¸ ë°ì´í„° ìºì‹œí™” ì‹œì‘ ===")
        
        # 3-1. ê° ì‚¬ì´íŠ¸ë³„ í´ë¼ì´ì–¸íŠ¸ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
        sites = [
            ('parafield_gardens_client.json', 'Parafield Gardens'),
            ('nerrilda_client.json', 'Nerrilda'),
            ('ramsay_client.json', 'Ramsay'),
            ('yankalilla_client.json', 'Yankalilla')
        ]
        
        for filename, site_name in sites:
            self.migrate_site_clients(filename, site_name)
        
        # 3-2. Client_list.jsonë„ ë°±ì—…ìœ¼ë¡œ ì²˜ë¦¬
        self.migrate_client_list()
        
        logger.info("=== Phase 3 ì™„ë£Œ ===")
    
    def migrate_site_clients(self, filename: str, site_name: str):
        """ê°œë³„ ì‚¬ì´íŠ¸ì˜ í´ë¼ì´ì–¸íŠ¸ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜"""
        filepath = f'data/{filename}'
        
        if not os.path.exists(filepath):
            logger.warning(f"{filepath} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        logger.info(f"{site_name} í´ë¼ì´ì–¸íŠ¸ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
        
        try:
            with open(filepath, 'r') as f:
                client_data = json.load(f)
            
            cursor = self.conn.cursor()
            count = 0
            
            # JSON êµ¬ì¡°ì— ë”°ë¼ ì²˜ë¦¬
            if isinstance(client_data, dict) and 'client_info' in client_data:
                clients = client_data['client_info']
            elif isinstance(client_data, list):
                clients = client_data
            else:
                logger.error(f"{filename}ì˜ JSON êµ¬ì¡°ë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            for client in clients:
                cursor.execute('''
                    INSERT OR REPLACE INTO clients_cache 
                    (person_id, client_name, preferred_name, title, first_name, 
                     middle_name, surname, gender, birth_date, admission_date,
                     room_name, room_number, wing_name, location_id, location_name,
                     main_client_service_id, original_person_id, client_record_id, site)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    client.get('PersonId') or client.get('MainClientServiceId'),
                    client.get('ClientName') or f"{client.get('FirstName', '')} {client.get('Surname', '')}".strip(),
                    client.get('PreferredName'),
                    client.get('Title'),
                    client.get('FirstName'),
                    client.get('MiddleName'),
                    client.get('Surname') or client.get('LastName'),
                    client.get('Gender'),
                    client.get('BirthDate'),
                    client.get('AdmissionDate'),
                    client.get('RoomName'),
                    client.get('RoomNumber'),
                    client.get('WingName'),
                    client.get('LocationId'),
                    client.get('LocationName'),
                    client.get('MainClientServiceId'),
                    client.get('OriginalPersonId'),
                    client.get('ClientRecordId'),
                    site_name
                ))
                count += 1
            
            self.conn.commit()
            
            # ë™ê¸°í™” ìƒíƒœ ì—…ë°ì´íŠ¸
            cursor.execute('''
                INSERT OR REPLACE INTO sync_status 
                (data_type, site, last_sync_time, sync_status, records_synced)
                VALUES (?, ?, ?, ?, ?)
            ''', ('clients', site_name, datetime.now().isoformat(), 'success', count))
            
            self.conn.commit()
            logger.info(f"{site_name} í´ë¼ì´ì–¸íŠ¸ {count}ëª… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"{site_name} í´ë¼ì´ì–¸íŠ¸ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
    
    def migrate_client_list(self):
        """data/Client_list.json ë§ˆì´ê·¸ë ˆì´ì…˜ (ë°±ì—… ë°ì´í„°)"""
        filepath = 'data/Client_list.json'
        
        if not os.path.exists(filepath):
            logger.warning(f"{filepath} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        logger.info("Client_list.json ë°±ì—… ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
        
        try:
            with open(filepath, 'r') as f:
                clients = json.load(f)
            
            cursor = self.conn.cursor()
            count = 0
            
            for client in clients:
                # ì¤‘ë³µ ì²´í¬ í›„ ì—†ëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                cursor.execute('''
                    SELECT COUNT(*) FROM clients_cache 
                    WHERE person_id = ? AND site = 'General'
                ''', (client.get('PersonId'),))
                
                if cursor.fetchone()[0] == 0:
                    cursor.execute('''
                        INSERT INTO clients_cache 
                        (person_id, client_name, preferred_name, gender, birth_date,
                         room_name, wing_name, main_client_service_id, 
                         original_person_id, client_record_id, site)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        client.get('PersonId'),
                        client.get('ClientName'),
                        client.get('PreferredName'),
                        client.get('Gender'),
                        client.get('BirthDate'),
                        client.get('RoomName'),
                        client.get('WingName'),
                        client.get('MainClientServiceId'),
                        client.get('OriginalPersonId'),
                        client.get('ClientRecordId'),
                        'General'  # ì¼ë°˜ ë°±ì—… ë°ì´í„°ë¡œ ë¶„ë¥˜
                    ))
                    count += 1
            
            self.conn.commit()
            logger.info(f"Client_list ë°±ì—… ë°ì´í„° {count}ëª… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"Client_list ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")

    # ===========================================
    # PHASE 4: í•˜ì´ë¸Œë¦¬ë“œ ë°ì´í„° ì²˜ë¦¬
    # ===========================================
    
    def phase4_migrate_hybrid_data(self):
        """Phase 4: ì¸ì‹œë˜íŠ¸ ë“± í•˜ì´ë¸Œë¦¬ë“œ ë°ì´í„° ì²˜ë¦¬"""
        logger.info("=== Phase 4: í•˜ì´ë¸Œë¦¬ë“œ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘ ===")
        
        # 4-1. ì¸ì‹œë˜íŠ¸ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
        self.migrate_incidents()
        
        logger.info("=== Phase 4 ì™„ë£Œ ===")
    
    def migrate_incidents(self):
        """incidents_*.json íŒŒì¼ë“¤ ë§ˆì´ê·¸ë ˆì´ì…˜"""
        data_dir = 'data'
        
        for filename in os.listdir(data_dir):
            if filename.startswith('incidents_') and filename.endswith('.json'):
                filepath = os.path.join(data_dir, filename)
                site_name = self.extract_site_from_filename(filename)
                self.migrate_incident_file(filepath, site_name)
    
    def extract_site_from_filename(self, filename: str) -> str:
        """íŒŒì¼ëª…ì—ì„œ ì‚¬ì´íŠ¸ëª… ì¶”ì¶œ"""
        if 'Parafield Gardens' in filename:
            return 'Parafield Gardens'
        return 'Unknown'
    
    def migrate_incident_file(self, filepath: str, site_name: str):
        """ê°œë³„ ì¸ì‹œë˜íŠ¸ íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜"""
        logger.info(f"{site_name} ì¸ì‹œë˜íŠ¸ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
        
        try:
            with open(filepath, 'r') as f:
                incidents = json.load(f)
            
            cursor = self.conn.cursor()
            count = 0
            
            for incident in incidents:
                cursor.execute('''
                    INSERT OR REPLACE INTO incidents_cache 
                    (incident_id, client_name, incident_type, incident_date, 
                     description, severity, status, site, reported_by)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    incident.get('id') or f"{site_name}_{count}",
                    incident.get('client_name'),
                    incident.get('type'),
                    incident.get('date'),
                    incident.get('description'),
                    incident.get('severity'),
                    incident.get('status'),
                    site_name,
                    incident.get('reported_by')
                ))
                count += 1
            
            self.conn.commit()
            logger.info(f"{site_name} ì¸ì‹œë˜íŠ¸ {count}ê°œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"{site_name} ì¸ì‹œë˜íŠ¸ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")

    # ===========================================
    # ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
    # ===========================================
    
    def run_full_migration(self):
        """ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰"""
        logger.info("ğŸš€ Progress Report System SQLite ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘ ğŸš€")
        start_time = datetime.now()
        
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
            self.connect()
            
            # ìŠ¤í‚¤ë§ˆ ìƒì„±
            self.create_schema()
            
            # Phase 1: í•µì‹¬ ì˜êµ¬ ë°ì´í„°
            self.phase1_migrate_core_data()
            
            # Phase 2: ì°¸ì¡° ë°ì´í„°
            self.phase2_migrate_reference_data()
            
            # Phase 3: í´ë¼ì´ì–¸íŠ¸ ë°ì´í„° ìºì‹œí™”
            self.phase3_migrate_client_data()
            
            # Phase 4: í•˜ì´ë¸Œë¦¬ë“œ ë°ì´í„°
            self.phase4_migrate_hybrid_data()
            
            # ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ ë¡œê·¸
            end_time = datetime.now()
            duration = end_time - start_time
            
            logger.info(f"ğŸ‰ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ! ì†Œìš”ì‹œê°„: {duration}")
            self.log_migration_summary()
            
        except Exception as e:
            logger.error(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
            raise
        finally:
            self.close()
    
    def create_schema(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ìƒì„±"""
        logger.info("ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ìƒì„± ì¤‘...")
        
        with open('database_schema.sql', 'r') as f:
            schema_sql = f.read()
        
        # SQL ë¬¸ë“¤ì„ ë¶„ë¦¬í•´ì„œ ì‹¤í–‰
        statements = schema_sql.split(';')
        cursor = self.conn.cursor()
        
        for statement in statements:
            statement = statement.strip()
            if statement and not statement.startswith('--'):
                try:
                    cursor.execute(statement)
                except sqlite3.Error as e:
                    if "already exists" not in str(e):
                        logger.error(f"ìŠ¤í‚¤ë§ˆ ìƒì„± ì˜¤ë¥˜: {e}")
        
        self.conn.commit()
        logger.info("ìŠ¤í‚¤ë§ˆ ìƒì„± ì™„ë£Œ")
    
    def log_migration_summary(self):
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ìš”ì•½ ë¡œê·¸"""
        cursor = self.conn.cursor()
        
        # ê° í…Œì´ë¸”ì˜ ë ˆì½”ë“œ ìˆ˜ í™•ì¸
        tables = [
            'users', 'fcm_tokens', 'access_logs', 'progress_note_logs',
            'clients_cache', 'care_areas', 'event_types', 'incidents_cache'
        ]
        
        logger.info("=== ë§ˆì´ê·¸ë ˆì´ì…˜ ìš”ì•½ ===")
        for table in tables:
            try:
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                count = cursor.fetchone()[0]
                logger.info(f"{table}: {count:,}ê°œ ë ˆì½”ë“œ")
            except sqlite3.Error:
                logger.info(f"{table}: í…Œì´ë¸” ì—†ìŒ")


# ===========================================
# ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
# ===========================================

if __name__ == "__main__":
    migration = ProgressReportMigration()
    migration.run_full_migration()
