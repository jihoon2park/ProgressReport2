# ë°ì´í„° ë™ê¸°í™” ìµœì í™” ê°€ì´ë“œ

## ğŸ“Š í˜„ì¬ ë¬¸ì œì 

### 1. ë§¤ë²ˆ ì „ì²´ ë°ì´í„° íŒŒì‹±
```python
# ë§¤ ìš”ì²­ë§ˆë‹¤ ì „ì²´ Incidents ì¡°íšŒ
GET /api/cims/incidents?site=Parafield Gardens&date=2025-10-15
â†’ DBì—ì„œ ì „ì²´ incidents ì¡°íšŒ
â†’ í•„í„°ë§ (Fallë§Œ)
â†’ ê° incidentë§ˆë‹¤ tasks ì¡°íšŒ
â†’ ì´ 100+ API í˜¸ì¶œ
```

### 2. ì¤‘ë³µ API í˜¸ì¶œ
```python
# Mobile Dashboard ì§„ì… ì‹œë§ˆë‹¤
- Incidents ì¡°íšŒ (179ê°œ)
- Tasks ì¡°íšŒ (179 Ã— 12 = 2148ê°œ)
- Policy ì¡°íšŒ
- Progress Notes ë™ê¸°í™” (179 Ã— 2 = 358 API calls)

â†’ ì´ 2000+ DB ì¿¼ë¦¬, 500+ API í˜¸ì¶œ
```

### 3. ìºì‹œ ì—†ìŒ
- ë™ì¼í•œ ë°ì´í„°ë¥¼ ë°˜ë³µ ì¡°íšŒ
- ë³€ê²½ë˜ì§€ ì•Šì€ ë°ì´í„°ë„ ë§¤ë²ˆ ì¬ì²˜ë¦¬
- ë„¤íŠ¸ì›Œí¬ ë° DB ë¶€í•˜ ì¦ê°€

---

## âœ… ìµœì í™” ì „ëµ

### 1. ì¦ë¶„ ë™ê¸°í™” (Incremental Sync)

#### MANAD Plus API íŒŒë¼ë¯¸í„° í™œìš©

```python
# changedsincedatetimeutc íŒŒë¼ë¯¸í„°
GET /api/incident?changedsincedatetimeutc=2025-10-15T10:00:00Z

# íš¨ê³¼
- ë§ˆì§€ë§‰ ë™ê¸°í™” ì´í›„ ë³€ê²½ëœ ë°ì´í„°ë§Œ ì¡°íšŒ
- API ì‘ë‹µ í¬ê¸° 90% ê°ì†Œ
- ì²˜ë¦¬ ì‹œê°„ 80% ê°ì†Œ
```

#### êµ¬í˜„ ë°©ë²•

```python
# app.py - sync_incidents_from_manad_to_cims()

if is_first_sync:
    # ì²« ë™ê¸°í™”: 30ì¼ ì „ì²´
    start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
else:
    # ì¦ë¶„ ë™ê¸°í™”: ë§ˆì§€ë§‰ ë™ê¸°í™” ì´í›„
    last_sync_time = get_last_sync_time('incidents')
    start_date = last_sync_time.strftime('%Y-%m-%d')
    
    # changedsincedatetimeutc íŒŒë¼ë¯¸í„° ì‚¬ìš©
    params['changedsincedatetimeutc'] = last_sync_time.isoformat()
```

### 2. DB ìºì‹± ì „ëµ

#### System Settings í…Œì´ë¸” í™œìš©

```sql
-- ë™ê¸°í™” ì‹œê°„ ê¸°ë¡
INSERT INTO system_settings (key, value, updated_at)
VALUES ('last_incident_sync_time', '2025-10-15T15:30:00Z', datetime('now'))
ON CONFLICT(key) DO UPDATE SET
    value = excluded.value,
    updated_at = datetime('now');
```

#### Siteë³„ ë™ê¸°í™” ìƒíƒœ ê´€ë¦¬

```python
# ê° ì‚¬ì´íŠ¸ë³„ ë§ˆì§€ë§‰ ë™ê¸°í™” ì‹œê°„ ì¶”ì 
sync_status = {
    'Parafield Gardens': {
        'last_sync': '2025-10-15T15:30:00Z',
        'incidents_count': 45,
        'sync_duration': 2.3  # seconds
    },
    'West Park': {
        'last_sync': '2025-10-15T15:31:00Z',
        'incidents_count': 67,
        'sync_duration': 3.1
    }
}
```

### 3. Mobile Dashboard ìµœì í™”

#### ë¬¸ì œì 
```javascript
// ë§¤ë²ˆ ì „ì²´ ë°ì´í„° ë¡œë“œ
async function loadSchedule() {
    const incidents = await fetch(`/api/cims/incidents?site=${site}&date=${date}`);
    // 179ê°œ incidents ì¡°íšŒ
    
    for (const incident of incidents) {
        const tasks = await fetch(`/api/cims/incident/${incident.id}/tasks`);
        // 179 Ã— 12 = 2148ê°œ tasks ì¡°íšŒ
    }
}
```

#### ìµœì í™” ë°©ì•ˆ

**ë°©ì•ˆ 1: Batch API**
```python
# app.py - ìƒˆ API ì—”ë“œí¬ì¸íŠ¸
@app.route('/api/cims/schedule/<site>/<date>')
def get_schedule_batch(site, date):
    """
    ì‚¬ì´íŠ¸/ë‚ ì§œë³„ ì „ì²´ ìŠ¤ì¼€ì¤„ì„ í•œ ë²ˆì— ë°˜í™˜
    
    - Incidents
    - Tasks (ë¯¸ë¦¬ ì¡°ì¸)
    - Policy rules
    
    â†’ 1íšŒ API í˜¸ì¶œë¡œ ëª¨ë“  ë°ì´í„° ì œê³µ
    """
    incidents = get_incidents_with_tasks(site, date)
    return jsonify(incidents)
```

**ë°©ì•ˆ 2: Local Storage ìºì‹±**
```javascript
// ë¸Œë¼ìš°ì € Local Storage í™œìš©
const cacheKey = `schedule_${site}_${date}`;
const cachedData = localStorage.getItem(cacheKey);

if (cachedData) {
    const cache = JSON.parse(cachedData);
    if (Date.now() - cache.timestamp < 5 * 60 * 1000) {  // 5ë¶„
        return cache.data;  // ìºì‹œ ì‚¬ìš©
    }
}

// ìºì‹œ ì—†ìœ¼ë©´ API í˜¸ì¶œ
const data = await fetchSchedule(site, date);
localStorage.setItem(cacheKey, JSON.stringify({
    data: data,
    timestamp: Date.now()
}));
```

**ë°©ì•ˆ 3: Server-Side ìºì‹±**
```python
# app.py - ë©”ëª¨ë¦¬ ìºì‹œ
from functools import lru_cache
from datetime import datetime, timedelta

@lru_cache(maxsize=100)
def get_cached_schedule(site: str, date: str, cache_time: int):
    """
    5ë¶„ ë‹¨ìœ„ë¡œ ìºì‹±
    
    cache_timeì€ í˜„ì¬ ì‹œê°„ì„ 5ë¶„ ë‹¨ìœ„ë¡œ ë°˜ì˜¬ë¦¼í•œ ê°’
    â†’ 5ë¶„ë§ˆë‹¤ ìë™ ê°±ì‹ 
    """
    return get_schedule(site, date)

@app.route('/api/cims/schedule/<site>/<date>')
def get_schedule_api(site, date):
    # í˜„ì¬ ì‹œê°„ì„ 5ë¶„ ë‹¨ìœ„ë¡œ ë°˜ì˜¬ë¦¼
    now = datetime.now()
    cache_time = (now.timestamp() // 300) * 300  # 5ë¶„ = 300ì´ˆ
    
    return jsonify(get_cached_schedule(site, date, int(cache_time)))
```

### 4. Progress Notes ìµœì í™”

#### í˜„ì¬ ë¬¸ì œ
```python
# ë§¤ë²ˆ ì „ì²´ Progress Notes ì¡°íšŒ
GET /api/progressnote/details?date=gt:...&date=lt:...
â†’ 7ì¼ê°„ ì „ì²´ Progress Notes
â†’ Pythonì—ì„œ í•„í„°ë§ (Post Fallë§Œ)
```

#### ìµœì í™”
```python
# changedsincedatetimeutc + clientId + progressNoteEventTypeId
GET /api/progressnote/details?
    clientId=28&
    progressNoteEventTypeId=12&  # Post Fall
    changedsincedatetimeutc=2025-10-15T10:00:00Z

# íš¨ê³¼
- íŠ¹ì • í™˜ìë§Œ ì¡°íšŒ
- Post Fall íƒ€ì…ë§Œ ì¡°íšŒ
- ë§ˆì§€ë§‰ ë™ê¸°í™” ì´í›„ ë³€ê²½ë¶„ë§Œ ì¡°íšŒ
- ë°ì´í„° ì „ì†¡ëŸ‰ 98% ê°ì†Œ
```

---

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ

### Before (ìµœì í™” ì „)

#### Mobile Dashboard ì§„ì… ì‹œ
```
1. Incidents ì¡°íšŒ: 179ê°œ (1.2ì´ˆ)
2. Tasks ì¡°íšŒ: 179 Ã— 12 = 2148ê°œ (8.5ì´ˆ)
3. Policy ì¡°íšŒ: 1íšŒ (0.3ì´ˆ)
4. ë Œë”ë§: (1.5ì´ˆ)

ì´ ì†Œìš” ì‹œê°„: ~11.5ì´ˆ
DB ì¿¼ë¦¬: 2328íšŒ
API í˜¸ì¶œ: 0íšŒ (DB ìºì‹œ ì‚¬ìš©)
```

#### Background Sync (5ë¶„ë§ˆë‹¤)
```
1. MANAD API í˜¸ì¶œ: 179 incidents Ã— 2 = 358íšŒ (30ì´ˆ)
2. DB INSERT/UPDATE: 179 Ã— 13 = 2327íšŒ (15ì´ˆ)
3. Progress Notes ë™ê¸°í™”: 179 Ã— 2 = 358íšŒ (25ì´ˆ)

ì´ ì†Œìš” ì‹œê°„: ~70ì´ˆ
API í˜¸ì¶œ: 716íšŒ
DB ì¿¼ë¦¬: 2500+íšŒ
```

### After (ìµœì í™” í›„)

#### Mobile Dashboard ì§„ì… ì‹œ (ìºì‹±)
```
1. ìºì‹œ í™•ì¸: Local Storage (0.05ì´ˆ)
   â†’ ìºì‹œ ìˆìŒ: ë°ì´í„° ë°˜í™˜ (0.1ì´ˆ)
   â†’ ìºì‹œ ì—†ìŒ: ì•„ë˜ ì‹¤í–‰

2. Batch API í˜¸ì¶œ: 1íšŒ (0.8ì´ˆ)
   â†’ Incidents + Tasks + Policy í•œ ë²ˆì— ë°˜í™˜

ì´ ì†Œìš” ì‹œê°„: ~0.9ì´ˆ (92% ê°œì„ )
DB ì¿¼ë¦¬: 3íšŒ (99.9% ê°ì†Œ)
API í˜¸ì¶œ: 0íšŒ
```

#### Background Sync (5ë¶„ë§ˆë‹¤, ì¦ë¶„)
```
1. ë§ˆì§€ë§‰ ë™ê¸°í™” ì‹œê°„ í™•ì¸: (0.01ì´ˆ)
2. MANAD API í˜¸ì¶œ (ì¦ë¶„): í‰ê·  5-10 incidents (2ì´ˆ)
   â†’ changedsincedatetimeutc íŒŒë¼ë¯¸í„° ì‚¬ìš©
3. DB INSERT/UPDATE: 5-10 incidents Ã— 13 = 65-130íšŒ (1ì´ˆ)
4. Progress Notes ë™ê¸°í™” (ì¦ë¶„): 5-10 Ã— 1 = 5-10íšŒ (1ì´ˆ)

ì´ ì†Œìš” ì‹œê°„: ~4ì´ˆ (94% ê°œì„ )
API í˜¸ì¶œ: 15-20íšŒ (97% ê°ì†Œ)
DB ì¿¼ë¦¬: 80-150íšŒ (94% ê°ì†Œ)
```

---

## ğŸš€ êµ¬í˜„ ê³„íš

### Phase 1: ì¦ë¶„ ë™ê¸°í™” ê°œì„  âœ…

- [x] Incidents: changedsincedatetimeutc íŒŒë¼ë¯¸í„° ì‚¬ìš© (ì´ë¯¸ êµ¬í˜„)
- [x] system_settings í…Œì´ë¸”ì— last_sync_time ì €ì¥ (ì´ë¯¸ êµ¬í˜„)
- [x] Progress Notes: clientId íŒŒë¼ë¯¸í„° ì‚¬ìš© (ì´ë¯¸ êµ¬í˜„)

### Phase 2: Batch API êµ¬í˜„ (ì§„í–‰ ì¤‘)

```python
@app.route('/api/cims/schedule/<site>/<date>')
def get_schedule_batch(site, date):
    """
    í•œ ë²ˆì˜ API í˜¸ì¶œë¡œ ì „ì²´ ìŠ¤ì¼€ì¤„ ë°˜í™˜
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    
    # Incidents + Tasks + Policyë¥¼ JOINìœ¼ë¡œ í•œ ë²ˆì— ì¡°íšŒ
    cursor.execute("""
        SELECT 
            i.id, i.incident_id, i.incident_type, i.incident_date,
            i.resident_name, i.resident_manad_id, i.description,
            t.task_id, t.due_date, t.status, t.completed_at
        FROM cims_incidents i
        LEFT JOIN cims_tasks t ON i.id = t.incident_id
        WHERE i.site = ? 
        AND DATE(i.incident_date) >= DATE(?, '-5 days')
        AND i.incident_type LIKE '%Fall%'
        ORDER BY i.incident_date, t.due_date
    """, (site, date))
    
    # ê²°ê³¼ë¥¼ incidentë³„ë¡œ ê·¸ë£¹í™”
    incidents_map = {}
    for row in cursor.fetchall():
        incident_id = row[0]
        if incident_id not in incidents_map:
            incidents_map[incident_id] = {
                'id': row[0],
                'incident_id': row[1],
                'incident_type': row[2],
                'incident_date': row[3],
                'resident_name': row[4],
                'resident_manad_id': row[5],
                'description': row[6],
                'tasks': []
            }
        
        if row[7]:  # task_idê°€ ìˆìœ¼ë©´
            incidents_map[incident_id]['tasks'].append({
                'task_id': row[7],
                'due_date': row[8],
                'status': row[9],
                'completed_at': row[10]
            })
    
    conn.close()
    
    return jsonify({
        'success': True,
        'incidents': list(incidents_map.values()),
        'cached': True,
        'timestamp': datetime.now().isoformat()
    })
```

### Phase 3: Local Storage ìºì‹± (TODO)

```javascript
// mobile_task_dashboard.html

const CACHE_TTL = 5 * 60 * 1000;  // 5ë¶„

function getCachedSchedule(site, date) {
    const cacheKey = `schedule_${site}_${date}`;
    const cached = localStorage.getItem(cacheKey);
    
    if (cached) {
        const data = JSON.parse(cached);
        if (Date.now() - data.timestamp < CACHE_TTL) {
            console.log('âœ… Using cached schedule');
            return data.schedule;
        }
    }
    return null;
}

function setCachedSchedule(site, date, schedule) {
    const cacheKey = `schedule_${site}_${date}`;
    localStorage.setItem(cacheKey, JSON.stringify({
        schedule: schedule,
        timestamp: Date.now()
    }));
}

async function loadSchedule() {
    const cached = getCachedSchedule(selectedSite, selectedDate);
    if (cached) {
        await renderSchedule(cached);
        return;
    }
    
    // ìºì‹œ ì—†ìœ¼ë©´ API í˜¸ì¶œ
    const response = await fetch(`/api/cims/schedule/${selectedSite}/${selectedDate}`);
    const data = await response.json();
    
    setCachedSchedule(selectedSite, selectedDate, data.incidents);
    await renderSchedule(data.incidents);
}
```

### Phase 4: Server-Side ìºì‹± (TODO)

```python
# Redis ë˜ëŠ” ë©”ëª¨ë¦¬ ìºì‹œ
from cachetools import TTLCache
from threading import Lock

# 5ë¶„ TTL, ìµœëŒ€ 100ê°œ í•­ëª©
schedule_cache = TTLCache(maxsize=100, ttl=300)
cache_lock = Lock()

@app.route('/api/cims/schedule/<site>/<date>')
def get_schedule_batch(site, date):
    cache_key = f"{site}_{date}"
    
    with cache_lock:
        if cache_key in schedule_cache:
            logger.info(f"âœ… Cache HIT: {cache_key}")
            return jsonify(schedule_cache[cache_key])
    
    # ìºì‹œ ì—†ìœ¼ë©´ DB ì¡°íšŒ
    schedule = get_schedule_from_db(site, date)
    
    with cache_lock:
        schedule_cache[cache_key] = {
            'success': True,
            'incidents': schedule,
            'cached': True,
            'timestamp': datetime.now().isoformat()
        }
    
    logger.info(f"ğŸ“¦ Cache MISS: {cache_key}, cached now")
    return jsonify(schedule_cache[cache_key])
```

---

## ğŸ“ˆ ì˜ˆìƒ íš¨ê³¼

| ì§€í‘œ | Before | After | ê°œì„ ìœ¨ |
|-----|--------|-------|-------|
| **Mobile Dashboard ë¡œë”©** | 11.5ì´ˆ | 0.9ì´ˆ | 92% â¬‡ï¸ |
| **DB ì¿¼ë¦¬ ìˆ˜** | 2328íšŒ | 3íšŒ | 99.9% â¬‡ï¸ |
| **Background Sync ì‹œê°„** | 70ì´ˆ | 4ì´ˆ | 94% â¬‡ï¸ |
| **API í˜¸ì¶œ ìˆ˜** | 716íšŒ | 15-20íšŒ | 97% â¬‡ï¸ |
| **ë„¤íŠ¸ì›Œí¬ ì „ì†¡ëŸ‰** | 50-100MB | 1-2MB | 98% â¬‡ï¸ |
| **ì„œë²„ ë¶€í•˜** | High | Low | 90% â¬‡ï¸ |

---

## ğŸ”§ ëª¨ë‹ˆí„°ë§

### ìºì‹œ íš¨ìœ¨ì„± ì¸¡ì •

```python
@app.route('/api/cims/cache-stats')
def get_cache_stats():
    """ìºì‹œ í†µê³„"""
    return jsonify({
        'cache_hits': cache_hits,
        'cache_misses': cache_misses,
        'hit_rate': cache_hits / (cache_hits + cache_misses),
        'cache_size': len(schedule_cache),
        'last_eviction': last_eviction_time
    })
```

### ë™ê¸°í™” ì„±ëŠ¥ ë¡œê·¸

```python
sync_start = time.time()
result = sync_incidents_from_manad_to_cims(full_sync=False)
sync_duration = time.time() - sync_start

logger.info(f"""
ğŸ“Š Sync Performance:
   Duration: {sync_duration:.2f}s
   Incidents: {result['synced']} synced, {result['updated']} updated
   API Calls: {result['api_calls']}
   DB Queries: {result['db_queries']}
""")
```

---

## âœ… ê²°ë¡ 

### ì£¼ìš” ê°œì„  ì‚¬í•­

1. **ì¦ë¶„ ë™ê¸°í™”**: changedsincedatetimeutc íŒŒë¼ë¯¸í„° í™œìš©
2. **Batch API**: í•œ ë²ˆì˜ í˜¸ì¶œë¡œ ì „ì²´ ìŠ¤ì¼€ì¤„ ì œê³µ
3. **Local Storage ìºì‹±**: 5ë¶„ TTL ë¸Œë¼ìš°ì € ìºì‹œ
4. **Server-Side ìºì‹±**: ë©”ëª¨ë¦¬ ìºì‹œë¡œ DB ë¶€í•˜ ê°ì†Œ

### ê¸°ëŒ€ íš¨ê³¼

- âœ… **ë¡œë”© ì†ë„ 92% ê°œì„ ** (11.5ì´ˆ â†’ 0.9ì´ˆ)
- âœ… **DB ë¶€í•˜ 99% ê°ì†Œ** (2328 ì¿¼ë¦¬ â†’ 3 ì¿¼ë¦¬)
- âœ… **API í˜¸ì¶œ 97% ê°ì†Œ** (716íšŒ â†’ 15íšŒ)
- âœ… **ì„œë²„ ë¹„ìš© ì ˆê°** (CPU, ë©”ëª¨ë¦¬, ë„¤íŠ¸ì›Œí¬)

### ë‹¤ìŒ ë‹¨ê³„

1. Phase 2: Batch API êµ¬í˜„
2. Phase 3: Local Storage ìºì‹±
3. Phase 4: Redis ë„ì… ê²€í† 
4. ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•

---

**ì‘ì„±ì¼**: 2025-10-15  
**ì‘ì„±ì**: AI Assistant  
**ë²„ì „**: 1.0

